"use strict";(self.webpackChunkso=self.webpackChunkso||[]).push([[4361],{5680:(e,t,a)=>{a.d(t,{xA:()=>d,yg:()=>u});var n=a(6540);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter(function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable})),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach(function(t){i(e,t,a[t])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach(function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))})}return e}function r(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},h="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef(function(e,t){var a=e.components,i=e.mdxType,s=e.originalType,l=e.parentName,d=r(e,["components","mdxType","originalType","parentName"]),h=c(a),m=i,u=h["".concat(l,".").concat(m)]||h[m]||p[m]||s;return a?n.createElement(u,o(o({ref:t},d),{},{components:a})):n.createElement(u,o({ref:t},d))});function u(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var s=a.length,o=new Array(s);o[0]=m;var r={};for(var l in t)hasOwnProperty.call(t,l)&&(r[l]=t[l]);r.originalType=e,r[h]="string"==typeof e?e:i,o[1]=r;for(var c=2;c<s;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},7983:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>c});var n=a(8168),i=(a(6540),a(5680));const s={},o="Lab 8 - Synchronization",r={unversionedId:"Compute/lab8",id:"Compute/lab8",title:"Lab 8 - Synchronization",description:"Task Race Conditions",source:"@site/docs/Compute/lab8.md",sourceDirName:"Compute",slug:"/Compute/lab8",permalink:"/operating-systems/Compute/lab8",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Lab 7 - Copy-on-Write",permalink:"/operating-systems/Compute/lab7"},next:{title:"IO",permalink:"/operating-systems/IO/"}},l={},c=[{value:"Task: C: Race Conditions",id:"task-c-race-conditions",level:2},{value:"Synchronization - Overhead",id:"synchronization---overhead",level:3},{value:"Task: Wrap the Whole <code>for</code> Statements in Critical Sections",id:"task-wrap-the-whole-for-statements-in-critical-sections",level:2},{value:"Task: C: Atomics",id:"task-c-atomics",level:2},{value:"Task: C - TLS on Demand",id:"task-c---tls-on-demand",level:2},{value:"Task: Atomic Assembly",id:"task-atomic-assembly",level:2},{value:"Guide: <code>apache2</code> Simulator - Semaphore",id:"guide-apache2-simulator---semaphore",level:2},{value:"Semaphores",id:"semaphores",level:3},{value:"Task: <code>apache2</code> Simulator - Condition",id:"task-apache2-simulator---condition",level:2},{value:"Conditions",id:"conditions",level:3},{value:"Synchronization",id:"synchronization",level:2},{value:"Race Conditions",id:"race-conditions",level:3},{value:"Thread-Local Storage (TLS)",id:"thread-local-storage-tls",level:3},{value:"User-Level Threads",id:"user-level-threads",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Creation",id:"creation",level:3},{value:"Practice: Sleeper Fiber",id:"practice-sleeper-fiber",level:4},{value:"No system calls",id:"no-system-calls",level:3},{value:"Synchronization",id:"synchronization-1",level:3},{value:"Yielding",id:"yielding",level:4},{value:"Practice",id:"practice",level:5},{value:"Barriers",id:"barriers",level:4},{value:"C++ unique_lock",id:"c-unique_lock",level:4},{value:"Scheduling",id:"scheduling",level:2},{value:"User-Level vs Kernel-Level Threads",id:"user-level-vs-kernel-level-threads",level:3},{value:"Thread Control Block",id:"thread-control-block",level:3},{value:"Scheduling - How is it done?",id:"scheduling---how-is-it-done",level:3},{value:"Cooperative Scheduling",id:"cooperative-scheduling",level:4},{value:"Preemptive Scheduling",id:"preemptive-scheduling",level:4},{value:"Guide: Interaction Between Threads and Fibers",id:"guide-interaction-between-threads-and-fibers",level:2},{value:"Guide: User-Level Threads Scheduler",id:"guide-user-level-threads-scheduler",level:2}],d={toc:c},h="wrapper";function p({components:e,...t}){return(0,i.yg)(h,(0,n.A)({},d,t,{components:e,mdxType:"MDXLayout"}),(0,i.yg)("h1",{id:"lab-8---synchronization"},"Lab 8 - Synchronization"),(0,i.yg)("h2",{id:"task-c-race-conditions"},"Task: C: Race Conditions"),(0,i.yg)("p",null,"Go to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/race-condition/support/c/race_condition_mutex.c")," and notice the differences between this code and the buggy one.\nWe now use a ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_mutex_t")," variable, which we ",(0,i.yg)("inlineCode",{parentName:"p"},"lock")," at the beginning of a critical section, and we ",(0,i.yg)("inlineCode",{parentName:"p"},"unlock")," at the end.\nGenerally speaking, ",(0,i.yg)("inlineCode",{parentName:"p"},"lock"),"-ing a mutex makes a thread enter a critical section, while calling ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_mutex_unlock()")," makes the thread leave said critical section.\nTherefore, as we said previously, the critical sections in our code are ",(0,i.yg)("inlineCode",{parentName:"p"},"var--")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"var++"),".\nRun the code multiple times to convince yourself that in the end, the value of ",(0,i.yg)("inlineCode",{parentName:"p"},"var")," will always be 0."),(0,i.yg)("p",null,"Mutexes contain an internal variable which can be either 1 (locked) or 0 (unlocked).\nWhen a thread calls ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_mutex_lock()"),", it attempts to set that variable to 1.\nIf it was 0, the thread sets it to 1 and proceeds to execute the critical section.\nOtherwise, it ",(0,i.yg)("strong",{parentName:"p"},"suspends its execution")," and waits until that variable is set to 0 again."),(0,i.yg)("p",null,"When calling ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_mutex_unlock()"),", the internal variable is set to 0 and all waiting threads are woken up to try to acquire the mutex again.\n",(0,i.yg)("strong",{parentName:"p"},"Be careful:")," It is generally considered unsafe and ",(0,i.yg)("a",{parentName:"p",href:"https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_mutex_lock.html"},"in many cases undefined behaviour")," to call ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_mutex_unlock()")," from a different thread than the one that acquired the lock.\nSo the general workflow should look something like this:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-text"},"within a single thread:\n    pthread_mutex_lock(&mutex)\n    // do atomic stuff\n    pthread_mutex_unlock(&mutex)\n")),(0,i.yg)("h3",{id:"synchronization---overhead"},"Synchronization - Overhead"),(0,i.yg)("blockquote",null,(0,i.yg)("p",{parentName:"blockquote"},"There ain't no such thing as a free lunch")),(0,i.yg)("p",null,"This saying is also true for multithreading.\nRunning threads in parallel is nice and efficient, but synchronization always comes with a penalty: overhead.\nUse the ",(0,i.yg)("inlineCode",{parentName:"p"},"time")," command to record the running times of ",(0,i.yg)("inlineCode",{parentName:"p"},"race_condition")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"race_condition_mutex"),".\nNotice that those of ",(0,i.yg)("inlineCode",{parentName:"p"},"race_condition_mutex")," are larger than those of ",(0,i.yg)("inlineCode",{parentName:"p"},"race_condition"),"."),(0,i.yg)("p",null,"The cause of this is that now when one thread is executing the critical section, the other has to wait and do nothing.\nWaiting means changing its state from RUNNING to WAITING, which brings further overhead from the scheduler.\nThis latter overhead comes from the ",(0,i.yg)("strong",{parentName:"p"},"context switch")," that is necessary for a thread to switch its state from RUNNING to WAITING and back."),(0,i.yg)("h2",{id:"task-wrap-the-whole-for-statements-in-critical-sections"},"Task: Wrap the Whole ",(0,i.yg)("inlineCode",{parentName:"h2"},"for")," Statements in Critical Sections"),(0,i.yg)("p",null,"Navigate to the ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/wrap-the-for/")," directory, run ",(0,i.yg)("inlineCode",{parentName:"p"},"make skels")," and open the ",(0,i.yg)("inlineCode",{parentName:"p"},"support/src")," directory."),(0,i.yg)("p",null,"Here you will find two source files:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"race_condition_inner_mutex"),(0,i.yg)("li",{parentName:"ul"},"race_condition_outer_mutex")),(0,i.yg)("p",null,"Following the pattern used in ",(0,i.yg)("inlineCode",{parentName:"p"},"race_condition_inner_mutex.c")," go in ",(0,i.yg)("inlineCode",{parentName:"p"},"race_condition_outer_mutex.c")," move the calls to ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_mutex_lock()")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_mutex_unlock()")," outside the ",(0,i.yg)("inlineCode",{parentName:"p"},"for")," statements so that the critical sections become the entire statement.\nTo see the time difference between the two implementations all you have to do is enter ",(0,i.yg)("inlineCode",{parentName:"p"},"tests/")," and run the checker."),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"cd ../tests/\n./checker.sh\n")),(0,i.yg)("p",null,"You should see in the terminal:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"Test passed\n")),(0,i.yg)("iframe",{id:"05190df7-4e9c-4b0a-a460-d596bd2749d6",srcdoc:'<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"><\/script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"><\/script><script>hljs.highlightAll();<\/script><div class="card d-flex" style="width: 75%; margin: auto; margin-top: 1rem; margin-bottom: 1rem;"> <div class="card-header" id="a19e55c1-354c-45df-a56a-8f4a58b5715a"> <p>Why does code with the the larger (coarser) critical section run faster than the one with the smaller (more granular) critical section?</p> </div> <ul class="list-group list-group-flush"> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="47fe34cd-5601-4f18-8ad9-c6a373e2241d"> <label class="form-check-label" for="47fe34cd-5601-4f18-8ad9-c6a373e2241d"> <p>Because the loops in the more granular code run for more steps</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="db96d31d-f6cc-4fe4-b3ff-838237f9f790"> <label class="form-check-label" for="db96d31d-f6cc-4fe4-b3ff-838237f9f790"> <p>Because the more granular code causes more context switches, which are expensive</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="3a60c19c-a2a3-428a-9517-92b516dc916f"> <label class="form-check-label" for="3a60c19c-a2a3-428a-9517-92b516dc916f"> <p>Because the coarser code can be better optimised by the compiler</p> </label> </div> </li> </ul> <div class="card-footer"> <div class="text-center" style="padding: 5px;"> <button class="check btn btn-primary" type="button" onclick="console.log(\'Clickedcheck\');answerIndex=\'db96d31d-f6cc-4fe4-b3ff-838237f9f790\';document.getElementsByClassName(\'check\')[0].classList.add(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=true;if(radio.checked){if(radio.id===answerIndex){choices[i].classList.add(\'list-group-item-success\');document.getElementsByClassName(\'feedback\')[0].classList.remove(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'feedback\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;}else{choices[i].classList.add(\'list-group-item-danger\');}}}">Check Answer </button> <button class="reset btn btn-default" type="button" onclick="console.log(\'Clickedreset\');document.getElementsByClassName(\'check\')[0].classList.remove(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=false;choices[i].classList.remove(\'list-group-item-success\');choices[i].classList.remove(\'list-group-item-danger\');radio.checked=false;}document.getElementsByClassName(\'feedback\')[0].classList.add(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'card\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;">Try Again</button> </div> </div></div><div class="feedback card d-flex d-none" style="width: 80%; margin: auto; margin-top: 1rem;"> <div class="card-header"> Feedback </div> <div class="card-body alert alert-success"> <p>The larger critical sections only require <strong>2 context switches</strong>.\nThe first thread that reaches the call to <code>lock()</code> acquires to the mutex and starts executing the whole of the <code>for</code> loop.\nThe second thread then finds the mutex <em>locked</em> and enters the WAITING state.\nWhen the first thread finishes its loop, it calls <code>unlock()</code> and wakes up the second thread, which acquires the lock and starts its loop.</p><p>In the more granular example, in the worst case, the holder of the mutex can change at every step of the loop.\nThis would mean 1 context switch per step per thread, i.e. <strong>20 million context switches</strong>.</p> </div></div>',width:"100%",style:{border:"none",overflow:"hidden"},onLoad:()=>{var e=document.getElementById("05190df7-4e9c-4b0a-a460-d596bd2749d6");e.height=e.contentWindow.document.body.scrollHeight+36}}),(0,i.yg)("h2",{id:"task-c-atomics"},"Task: C: Atomics"),(0,i.yg)("p",null,"So now we know how to use mutexes.\nAnd we know that mutexes work by using an internal variable that can be either 1 (locked) or 0 (unlocked).\nBut how does ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_mutex_lock()")," actually set that variable to 1?\nHow does it avoid a race condition in case another thread also wants to set it to 1?"),(0,i.yg)("p",null,'We need a guarantee that anyone "touching" that variable does so "within its own critical section".\nBut now we need a critical section to implement a critical section...\nTo solve this circular problem, we make use of a very common ',(0,i.yg)("em",{parentName:"p"},"Deus ex Machina"),": ",(0,i.yg)("strong",{parentName:"p"},"hardware support"),"."),(0,i.yg)("p",null,"Modern processors are capable of ",(0,i.yg)("em",{parentName:"p"},"atomically")," accessing data, either for reads or writes.\nAn atomic action is an indivisible sequence of operations that a thread runs without interference from others.\nConcretely, before initiating an atomic transfer on one of its data buses, the CPU first makes sure all other transfers have ended, then ",(0,i.yg)("strong",{parentName:"p"},"locks")," the data bus by stalling all cores attempting to transfer data on it.\nThis way, one thread obtains ",(0,i.yg)("strong",{parentName:"p"},"exclusive")," access to the data bus while accessing data.\nAs a side note, the critical sections in ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/race-condition/support/c/race_condition_mutex.c")," are also atomic once they are wrapped between calls to ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_mutex_lock()")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_mutex_unlock()"),"."),(0,i.yg)("p",null,"As with every hardware feature, the ",(0,i.yg)("inlineCode",{parentName:"p"},"x86")," ISA exposes an instruction for atomic operations.\nIn particular, this instruction is a ",(0,i.yg)("strong",{parentName:"p"},"prefix"),", called ",(0,i.yg)("inlineCode",{parentName:"p"},"lock"),".\nIt makes the instruction that follows it run atomically.\nThe ",(0,i.yg)("inlineCode",{parentName:"p"},"lock")," prefix ensures that the core performing the instruction has exclusive ownership of the cache line from where the data is transferred for the entire operation.\nThis is how the increment is made into an indivisible unit."),(0,i.yg)("p",null,"For example, ",(0,i.yg)("inlineCode",{parentName:"p"},"inc dword [x]")," can be made atomic, like so: ",(0,i.yg)("inlineCode",{parentName:"p"},"lock inc dword [x]"),"."),(0,i.yg)("p",null,"Compilers provide support for such hardware-level atomic operations.\nGCC exposes ",(0,i.yg)("a",{parentName:"p",href:"https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html"},"built-ins")," such as ",(0,i.yg)("inlineCode",{parentName:"p"},"__atomic_load()"),", ",(0,i.yg)("inlineCode",{parentName:"p"},"__atomic_store()"),", ",(0,i.yg)("inlineCode",{parentName:"p"},"__atomic_compare_exchange()")," and many others.\nAll of them rely on the mechanism described above."),(0,i.yg)("p",null,"Go to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/race-condition-atomic/")," and run:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"make skels\n")),(0,i.yg)("p",null,"Now enter ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/race-condition-atomic/support/src/race_condition_atomic.c")," and complete the function ",(0,i.yg)("inlineCode",{parentName:"p"},"decrement_var()"),".\nCompile and run the code.\nIts running time should be somewhere between ",(0,i.yg)("inlineCode",{parentName:"p"},"race_condition")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"race_condition_mutex"),"."),(0,i.yg)("p",null,"The C standard library also provides atomic data types.\nAccess to these variables can be done only by one thread at a time.\nGo to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/race-condition-atomic/support/race_condition_atomic2.c"),", compile and run the code."),(0,i.yg)("p",null,"After both tasks are done, go in the checker folder and run it using the following commands:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"cd ../tests/\n./checker.sh\n")),(0,i.yg)("p",null,"Notice that the time is similar to ",(0,i.yg)("inlineCode",{parentName:"p"},"race_condition_atomic"),"."),(0,i.yg)("p",null,"So using the hardware support is more efficient, but it usually is leveraged only for simple, individual instructions, such as loads and stores.\nAnd the fact that high-level languages also expose an API for atomic operations shows how useful these operations are for developers."),(0,i.yg)("h2",{id:"task-c---tls-on-demand"},"Task: C - TLS on Demand"),(0,i.yg)("p",null,"The perspective of C towards TLS is the following: everything is shared by default.\nThis makes multithreading easier and more lightweight to implement than in other languages, like D, because synchronization is left entirely up to the developer, at the cost of potential unsafety."),(0,i.yg)("p",null,"Of course, we can specify that some data belongs to the TLS, by preceding the declaration of a variable with ",(0,i.yg)("inlineCode",{parentName:"p"},"__thread")," keyword.\nEnter ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/tls-on-demand/")," and run ",(0,i.yg)("inlineCode",{parentName:"p"},"make skels"),".\nNow enter ",(0,i.yg)("inlineCode",{parentName:"p"},"support/src")," and follow the TODOs."),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Create the declaration of ",(0,i.yg)("inlineCode",{parentName:"p"},"var")," and add the ",(0,i.yg)("inlineCode",{parentName:"p"},"__thread")," keyword to place the variable in the TLS of each thread.\nRecompile and run the code a few more times.\nYou should see that in the end, ",(0,i.yg)("inlineCode",{parentName:"p"},"var")," is 0.")),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Print the address and value of ",(0,i.yg)("inlineCode",{parentName:"p"},"var")," in each thread.\nSee that they differ.")),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Modify the value of ",(0,i.yg)("inlineCode",{parentName:"p"},"var")," in the ",(0,i.yg)("inlineCode",{parentName:"p"},"main()")," function before calling ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_create()"),".\nNotice that the value doesn't propagate to the other threads.\nThis is because, upon creating a new thread, its TLS is initialised."))),(0,i.yg)("p",null,(0,i.yg)("a",{parentName:"p",href:"questions/tls-synchronization.md"},"Quiz 1")),(0,i.yg)("iframe",{id:"9cf40cca-c73e-4ce4-95ad-eb384d5e1723",srcdoc:'<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"><\/script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"><\/script><script>hljs.highlightAll();<\/script><div class="card d-flex" style="width: 75%; margin: auto; margin-top: 1rem; margin-bottom: 1rem;"> <div class="card-header" id="ae223219-b7cc-499d-a67e-2a7a0da103e8"> <p>How many copies of the <code>var</code> variable from <code>support/race-condition/c/race_condition_tls.c</code> are there after each thread has modified it at leas once?</p> </div> <ul class="list-group list-group-flush"> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="f520d989-6fea-49ce-87ec-0c2bd16b80e4"> <label class="form-check-label" for="f520d989-6fea-49ce-87ec-0c2bd16b80e4"> <p>2</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="520cc9d5-d53f-4717-a2cb-a23d3a43f678"> <label class="form-check-label" for="520cc9d5-d53f-4717-a2cb-a23d3a43f678"> <p>5</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="cc0d01d2-f291-4b23-9cd5-c563188c9ef9"> <label class="form-check-label" for="cc0d01d2-f291-4b23-9cd5-c563188c9ef9"> <p>1</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="af45de2a-15b6-4149-86a6-6cc72319e475"> <label class="form-check-label" for="af45de2a-15b6-4149-86a6-6cc72319e475"> <p>3</p> </label> </div> </li> </ul> <div class="card-footer"> <div class="text-center" style="padding: 5px;"> <button class="check btn btn-primary" type="button" onclick="console.log(\'Clickedcheck\');answerIndex=\'af45de2a-15b6-4149-86a6-6cc72319e475\';document.getElementsByClassName(\'check\')[0].classList.add(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=true;if(radio.checked){if(radio.id===answerIndex){choices[i].classList.add(\'list-group-item-success\');document.getElementsByClassName(\'feedback\')[0].classList.remove(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'feedback\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;}else{choices[i].classList.add(\'list-group-item-danger\');}}}">Check Answer </button> <button class="reset btn btn-default" type="button" onclick="console.log(\'Clickedreset\');document.getElementsByClassName(\'check\')[0].classList.remove(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=false;choices[i].classList.remove(\'list-group-item-success\');choices[i].classList.remove(\'list-group-item-danger\');radio.checked=false;}document.getElementsByClassName(\'feedback\')[0].classList.add(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'card\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;">Try Again</button> </div> </div></div><div class="feedback card d-flex d-none" style="width: 80%; margin: auto; margin-top: 1rem;"> <div class="card-header"> Feedback </div> <div class="card-body alert alert-success"> <p>There are 3 copies one for the <code>main()</code> thread, another one for <code>increment_var()</code> and the third for <code>decrement_var()</code>.</p> </div></div>',width:"100%",style:{border:"none",overflow:"hidden"},onLoad:()=>{var e=document.getElementById("9cf40cca-c73e-4ce4-95ad-eb384d5e1723");e.height=e.contentWindow.document.body.scrollHeight+36}}),(0,i.yg)("h2",{id:"task-atomic-assembly"},"Task: Atomic Assembly"),(0,i.yg)("p",null,"No, this section is not about nukes, sadly :(.\nInstead, we aim to get accustomed to the way in which the x86 ISA provides atomic instructions."),(0,i.yg)("p",null,"This mechanism looks very simple.\nIt is but ",(0,i.yg)("strong",{parentName:"p"},"one instruction prefix"),": ",(0,i.yg)("inlineCode",{parentName:"p"},"lock"),".\nIt is not an instruction with its own separate opcode, but a prefix that slightly modifies the opcode of the following instructions to make the CPU execute it atomically (i.e. with exclusive access to the data bus)."),(0,i.yg)("p",null,(0,i.yg)("inlineCode",{parentName:"p"},"lock")," must only be place before an instruction that executes a ",(0,i.yg)("em",{parentName:"p"},"read-modify-write")," action.\nFor example, we cannot place it before a ",(0,i.yg)("inlineCode",{parentName:"p"},"mov")," instruction, as the action of a ",(0,i.yg)("inlineCode",{parentName:"p"},"mov")," is simply ",(0,i.yg)("inlineCode",{parentName:"p"},"read")," or ",(0,i.yg)("inlineCode",{parentName:"p"},"write"),".\nInstead, we can place it in front of an ",(0,i.yg)("inlineCode",{parentName:"p"},"inc")," instruction if its operand is memory."),(0,i.yg)("p",null,"Go in ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/atomic-assembly/")," and run:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"make skels\n")),(0,i.yg)("p",null,"Look at the code in ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/atomic-assembly/support/src/race_condition_lock.asm"),".\nIt's an Assembly equivalent of the code you've already seen many times so far (such as ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/race-condition/support/c/race_condition.c"),").\nThe 2 assembly functions (",(0,i.yg)("strong",{parentName:"p"},"increment_var")," and ",(0,i.yg)("strong",{parentName:"p"},"decrement_var"),") are called by ",(0,i.yg)("inlineCode",{parentName:"p"},"race_condition_lock_checker.c")),(0,i.yg)("p",null,"Now add the ",(0,i.yg)("inlineCode",{parentName:"p"},"lock")," prefix before ",(0,i.yg)("inlineCode",{parentName:"p"},"dec"),".\nGo in the ",(0,i.yg)("inlineCode",{parentName:"p"},"tests/")," folder and run the checker:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},"cd ../tests/\n./checker.sh\n")),(0,i.yg)("p",null,"You should see something like this, if done correctly:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-text"},"Building the project...\n\nnasm -f elf64 -o race_condition_lock.o race_condition_lock.asm\ngcc -no-pie -o race_condition_lock_checker race_condition_lock_checker.c race_condition_lock.o -lpthread\nChecking if var == 0...\n\nTest passed\n")),(0,i.yg)("p",null,"And now we have synchronized the two threads by leveraging CPU support."),(0,i.yg)("h2",{id:"guide-apache2-simulator---semaphore"},"Guide: ",(0,i.yg)("inlineCode",{parentName:"h2"},"apache2")," Simulator - Semaphore"),(0,i.yg)("h3",{id:"semaphores"},"Semaphores"),(0,i.yg)("p",null,"Up to now, we've learned how to create critical sections that can be accessed by ",(0,i.yg)("strong",{parentName:"p"},"only one thread")," at a time.\nThese critical sections revolved around ",(0,i.yg)("strong",{parentName:"p"},"data"),".\nWhenever we define a critical section, there is some specific data to which we cannot allow parallel access.\nThe reason why we can't allow it is, in general, data integrity, as we've seen in our examples in ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/race-condition/support/")),(0,i.yg)("p",null,"But what if threads need to count?\nCounting is inherently thread-unsafe because it's a ",(0,i.yg)("em",{parentName:"p"},"read-modify-write")," operation.\nWe read the counter, increment (modify) it and then write it back.\nThink about our example with ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/Compute/lab7#usage-of-processes-and-threads-in-apache2"},(0,i.yg)("inlineCode",{parentName:"a"},"apache2")),"\nLet's say a ",(0,i.yg)("inlineCode",{parentName:"p"},"worker")," has created a ",(0,i.yg)("em",{parentName:"p"},"pool")," of 3 threads.\nThey are not doing any work initially;\nthey are in the WAITING state.\nAs clients initiate connections, these threads are picked up and are used to serve ",(0,i.yg)("strong",{parentName:"p"},"at most 3")," connections at a time.\nBut the number of connections may be arbitrarily large.\nTherefore, we need a way to keep track of it.\nWhen serving a client, a thread should decrement it to inform the others that a connection has been finished.\nIn short, we need a counter that the dispatcher increments and that worker threads decrement."),(0,i.yg)("p",null,"Such a counter could be implemented using a ",(0,i.yg)("strong",{parentName:"p"},"semaphore"),".\nFor simplicity's sake, you can view a semaphore as simply a mutex whose internal variable can take any value and acts like a counter.\nWhen a thread attempts to ",(0,i.yg)("inlineCode",{parentName:"p"},"acquire()")," a semaphore, it will wait if this counter is less than or equal to 0.\nOtherwise, the thread ",(0,i.yg)("strong",{parentName:"p"},"decrements")," the internal counter and the function returns.\nThe opposite of ",(0,i.yg)("inlineCode",{parentName:"p"},"acquire()")," is ",(0,i.yg)("inlineCode",{parentName:"p"},"release()"),", which increases the internal counter by a given value (by default 1)."),(0,i.yg)("p",null,"Go to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/guides/apache2-simulator-semaphore/support/apache2_simulator_semaphore.py"),".\nIn the ",(0,i.yg)("inlineCode",{parentName:"p"},"main()")," function we create a semaphore which we increment (",(0,i.yg)("inlineCode",{parentName:"p"},"release()"),") upon every new message.\nEach thread decrements (",(0,i.yg)("inlineCode",{parentName:"p"},"acquire()"),") this semaphore to signal that it wants to retrieve a message from the list.\nThe retrieval means modifying a data structure, which is a critical section, so we use a ",(0,i.yg)("strong",{parentName:"p"},"separate")," mutex for this.\nOtherwise, multiple threads could acquire the semaphore at the same time and try to modify the list at the same time.\nNot good."),(0,i.yg)("p",null,"Locking this mutex (which in Python is called ",(0,i.yg)("inlineCode",{parentName:"p"},"Lock"),") is done with the following statement: ",(0,i.yg)("inlineCode",{parentName:"p"},"with msg_mutex:"),"\nThis is a syntactic equivalent to:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-Python"},"event.acquire()\nmessages.append(msg)\nevent.release()\n")),(0,i.yg)("p",null,"Since the length of the ",(0,i.yg)("inlineCode",{parentName:"p"},"messages")," list is simply ",(0,i.yg)("inlineCode",{parentName:"p"},"len(messages)"),", it may seem a bit redundant to use a semaphore to store essentially the same value.\nIn the next section, we'll look at a more refined mechanism for our use case: ",(0,i.yg)("em",{parentName:"p"},"condition variables"),"."),(0,i.yg)("iframe",{id:"af8a54e4-b114-4b60-83c0-23a2ffbb28e9",srcdoc:'<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"><\/script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"><\/script><script>hljs.highlightAll();<\/script><div class="card d-flex" style="width: 75%; margin: auto; margin-top: 1rem; margin-bottom: 1rem;"> <div class="card-header" id="96bcd318-0f0c-4be6-b309-9d47e796ede0"> <p>From running and inspecting the code in <code>support/apache2-simulator/apache2_simulator_semaphore.py</code>, which of the following is an an equivalent to the value of the semaphore <code>sem</code>?</p> </div> <ul class="list-group list-group-flush"> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="0aebae06-1911-4743-aa68-c147f6997138"> <label class="form-check-label" for="0aebae06-1911-4743-aa68-c147f6997138"> <p>The time a worker thread has to wait before running</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="2ea1a1e0-8ee6-47da-bfdb-06d8b4e6dfd4"> <label class="form-check-label" for="2ea1a1e0-8ee6-47da-bfdb-06d8b4e6dfd4"> <p>The number of worker threads</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="f21a5582-8886-4b8d-ae55-22432e97a24a"> <label class="form-check-label" for="f21a5582-8886-4b8d-ae55-22432e97a24a"> <p>The length of the <code>messages</code> list</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="b3f244ac-5d07-412f-9ef0-2b78944556a7"> <label class="form-check-label" for="b3f244ac-5d07-412f-9ef0-2b78944556a7"> <p>The value of <code>msg_mutex</code></p> </label> </div> </li> </ul> <div class="card-footer"> <div class="text-center" style="padding: 5px;"> <button class="check btn btn-primary" type="button" onclick="console.log(\'Clickedcheck\');answerIndex=\'f21a5582-8886-4b8d-ae55-22432e97a24a\';document.getElementsByClassName(\'check\')[0].classList.add(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=true;if(radio.checked){if(radio.id===answerIndex){choices[i].classList.add(\'list-group-item-success\');document.getElementsByClassName(\'feedback\')[0].classList.remove(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'feedback\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;}else{choices[i].classList.add(\'list-group-item-danger\');}}}">Check Answer </button> <button class="reset btn btn-default" type="button" onclick="console.log(\'Clickedreset\');document.getElementsByClassName(\'check\')[0].classList.remove(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=false;choices[i].classList.remove(\'list-group-item-success\');choices[i].classList.remove(\'list-group-item-danger\');radio.checked=false;}document.getElementsByClassName(\'feedback\')[0].classList.add(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'card\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;">Try Again</button> </div> </div></div><div class="feedback card d-flex d-none" style="width: 80%; margin: auto; margin-top: 1rem;"> <div class="card-header"> Feedback </div> <div class="card-body alert alert-success"> <p><code>sem</code> is incremented (<code>release()</code>) upon adding a message to the <code>messages</code> list and decremented (<code>acquire()</code>) when removing a message from said list.\nSo it\'s a rough equivalent to the length of this list.</p> </div></div>',width:"100%",style:{border:"none",overflow:"hidden"},onLoad:()=>{var e=document.getElementById("af8a54e4-b114-4b60-83c0-23a2ffbb28e9");e.height=e.contentWindow.document.body.scrollHeight+36}}),(0,i.yg)("h2",{id:"task-apache2-simulator---condition"},"Task: ",(0,i.yg)("inlineCode",{parentName:"h2"},"apache2")," Simulator - Condition"),(0,i.yg)("h3",{id:"conditions"},"Conditions"),(0,i.yg)("p",null,"Another way we can implement our ",(0,i.yg)("inlineCode",{parentName:"p"},"apache2")," simulator is to use a condition variable.\nThis one is probably the most intuitive synchronization primitive.\nIt's a means by which a thread can tell another one: \"Hey, wake up, ",(0,i.yg)("em",{parentName:"p"},"this")," happened!\".\nSo it's a way for threads to notify each other.\nFor this reason, the main methods associated with conditions are ",(0,i.yg)("inlineCode",{parentName:"p"},"notify()")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"wait()"),".\nAs you might expect, they are complementary:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"wait()")," puts the thread in the WAITING state until it's woken up by another one"),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"notify()")," wakes up one or more ",(0,i.yg)("inlineCode",{parentName:"li"},"wait()"),"-ing threads.\nIf ",(0,i.yg)("inlineCode",{parentName:"li"},"notify()")," is called before any thread has called ",(0,i.yg)("inlineCode",{parentName:"li"},"wait()"),", the first thread that calls it will continue its execution unhindered.")),(0,i.yg)("p",null,"Let's talk about a classic problem in synchronization and parallel computing: ",(0,i.yg)("strong",{parentName:"p"},"The producer-consumer problem"),"\nThe problem states that one or more producers generate data and places it in a shared buffer (a queue for example), while one or more consumers take data from the buffer to further process it.\nMore about it in this ",(0,i.yg)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=Qx3P2wazwI0"},"video"),".\nThere are a few rules though, such as:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"The producer must not insert data when the buffer is full."),(0,i.yg)("li",{parentName:"ul"},"The consumer must not retrieve data if the buffer is empty."),(0,i.yg)("li",{parentName:"ul"},"The producer and the consumer can't access the shared buffer at the same time.")),(0,i.yg)("p",null,"Now enter ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/apache2-simulator-condition/")," and run ",(0,i.yg)("inlineCode",{parentName:"p"},"make skels"),".\nLook at the code in ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/apache2-simulator/support/src/producer_consumer.py"),".\nWe have one producer and one consumer for simplicity.\nObserve that the producer calls ",(0,i.yg)("inlineCode",{parentName:"p"},"notify()")," once there is data available, and the consumer calls ",(0,i.yg)("inlineCode",{parentName:"p"},"notify()"),", when data is read.\nNotice that this call is preceded by an ",(0,i.yg)("inlineCode",{parentName:"p"},"acquire()")," call, and succeeded by a ",(0,i.yg)("inlineCode",{parentName:"p"},"release()")," call."),(0,i.yg)("p",null,(0,i.yg)("inlineCode",{parentName:"p"},"acquire()")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"release()")," are commonly associated with mutexes or semaphores.\nWhat do they have to do with condition variables?"),(0,i.yg)("p",null,"Well, a lock ",(0,i.yg)("inlineCode",{parentName:"p"},"Condition")," variable also stores an inner lock (mutex).\nIt is this lock that we ",(0,i.yg)("inlineCode",{parentName:"p"},"acquire()")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"release()"),".\nIn fact, the ",(0,i.yg)("a",{parentName:"p",href:"https://docs.python.org/3/library/threading.html#condition-objects"},"documentation")," states we should only call ",(0,i.yg)("inlineCode",{parentName:"p"},"Condition")," methods with its inner lock taken."),(0,i.yg)("p",null,"Why is this necessary?\nWe don't want both the consumer and the producer to modify a buffer at the same time, this could lead to a race condition, especially if we have more producers and more consumers."),(0,i.yg)("p",null,"So now we know we cannot only use a mutex.\nThe mutex is used to access and modify the ",(0,i.yg)("inlineCode",{parentName:"p"},"queue")," atomically.\nNow, you might be thinking that this code causes a deadlock:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-Python"},"condition.acquire()\n    with condition:\n    ...\n    condition.wait()\n")),(0,i.yg)("p",null,"The thread gets the lock and then, if there is no data, it switches its state to WAITING.\nA classic deadlock, right?\nNo.\n",(0,i.yg)("inlineCode",{parentName:"p"},"wait()")," also releases the inner lock of the ",(0,i.yg)("inlineCode",{parentName:"p"},"Condition")," and being woken up reacquires it.\nNeat!"),(0,i.yg)("p",null,"So now we have both synchronization ",(0,i.yg)("strong",{parentName:"p"},"and")," signalling.\nThis is what conditions are for, ultimately."),(0,i.yg)("p",null,"Open ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/apache2-simulator/support/src/apache2_simulator_condition.py")," and follow the TODOs.\nThe code is similar to ",(0,i.yg)("inlineCode",{parentName:"p"},"apache2_simulator_semaphore.py"),", but this time we use condition variables as shown in ",(0,i.yg)("inlineCode",{parentName:"p"},"producer_consumer.py"),"."),(0,i.yg)("iframe",{id:"4552a330-2317-4591-bd59-2512c84f502f",srcdoc:'<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"><\/script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"><\/script><script>hljs.highlightAll();<\/script><div class="card d-flex" style="width: 75%; margin: auto; margin-top: 1rem; margin-bottom: 1rem;"> <div class="card-header" id="bb97a2dc-6e68-450b-b70c-b7733b98734c"> <p>Can we only use a mutex when signalling an event from one thread to another in?</p> </div> <ul class="list-group list-group-flush"> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="a11c2f62-d0dd-4efd-b34e-767f3051aeb1"> <label class="form-check-label" for="a11c2f62-d0dd-4efd-b34e-767f3051aeb1"> <p>Yes and this would yield better performance because the threads would only wait for one object: the mutex</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="581cd4f0-380d-4b62-995c-c3b880e0e308"> <label class="form-check-label" for="581cd4f0-380d-4b62-995c-c3b880e0e308"> <p>No, because this would imply that the signalling thread would <code>unlock()</code> the mutex, that the signalled thread attempts to <code>lock()</code>, which is an undefined behaviour</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="d7f7dd93-e726-49aa-8dba-4fbfd31182a2"> <label class="form-check-label" for="d7f7dd93-e726-49aa-8dba-4fbfd31182a2"> <p>Yes, because only one thread can modify the shared variables in order to maintain their integrity</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="39afa0e0-ed4d-4093-8229-5b6ad4384c36"> <label class="form-check-label" for="39afa0e0-ed4d-4093-8229-5b6ad4384c36"> <p>No, because it will result in a deadlock where the both threads will be waiting for each other</p> </label> </div> </li> </ul> <div class="card-footer"> <div class="text-center" style="padding: 5px;"> <button class="check btn btn-primary" type="button" onclick="console.log(\'Clickedcheck\');answerIndex=\'581cd4f0-380d-4b62-995c-c3b880e0e308\';document.getElementsByClassName(\'check\')[0].classList.add(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=true;if(radio.checked){if(radio.id===answerIndex){choices[i].classList.add(\'list-group-item-success\');document.getElementsByClassName(\'feedback\')[0].classList.remove(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'feedback\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;}else{choices[i].classList.add(\'list-group-item-danger\');}}}">Check Answer </button> <button class="reset btn btn-default" type="button" onclick="console.log(\'Clickedreset\');document.getElementsByClassName(\'check\')[0].classList.remove(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=false;choices[i].classList.remove(\'list-group-item-success\');choices[i].classList.remove(\'list-group-item-danger\');radio.checked=false;}document.getElementsByClassName(\'feedback\')[0].classList.add(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'card\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;">Try Again</button> </div> </div></div><div class="feedback card d-flex d-none" style="width: 80%; margin: auto; margin-top: 1rem;"> <div class="card-header"> Feedback </div> <div class="card-body alert alert-success"> <p>In some implementations, such as <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_mutex_lock.html">POSIX threads (pthreads)</a>, calling <code>unlock()</code> from another thread than that which called <code>lock()</code> can result in an undefined behaviour.\nFor this reason, it is unsafe to only use a mutex as a notification mechanism.\nIn addition, a mutex cannot notify more than one thread at once, if we so desire.\nMutexes are only meant to be used to isolate a critical section within the same thread.</p> </div></div>',width:"100%",style:{border:"none",overflow:"hidden"},onLoad:()=>{var e=document.getElementById("4552a330-2317-4591-bd59-2512c84f502f");e.height=e.contentWindow.document.body.scrollHeight+36}}),(0,i.yg)("h2",{id:"synchronization"},"Synchronization"),(0,i.yg)("p",null,'So far, we\'ve used threads and processes without wondering how to "tell" them how to access shared data.\nMoreover, in order to make threads wait for each other, we simply had the main thread wait for the others to finish all their work.\nBut what if we want one thread to wait until another one simply performs some specific action, after which it resumes its execution?\nFor this, we need to use some more complex synchronization mechanisms.'),(0,i.yg)("h3",{id:"race-conditions"},"Race Conditions"),(0,i.yg)("p",null,"For example, what if one thread wants to increase a global variable while another one wants to decrease it?\nLet's say the assembly code for increasing and decreasing the variable looks like the one in the snippet below."),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-asm"},"increase:\n    mov eax, [var]\n    inc eax\n    mov [var], eax\n\ndecrease:\n    mov eax, [var]\n    dec eax\n    mov [var], eax\n")),(0,i.yg)("p",null,"Imagine both threads executed ",(0,i.yg)("inlineCode",{parentName:"p"},"mov eax, [var]")," at the same time.\nThen each would independently increase its (",(0,i.yg)("strong",{parentName:"p"},"non-shared"),") ",(0,i.yg)("inlineCode",{parentName:"p"},"eax")," register.\nIn the end, the final value of ",(0,i.yg)("inlineCode",{parentName:"p"},"var")," depends on which thread executes ",(0,i.yg)("inlineCode",{parentName:"p"},"mov [var], eax")," ",(0,i.yg)("em",{parentName:"p"},"last"),'.\nSo it\'s kind of a reversed race.\nThe thread that runs the slowest "wins" this race and writes the final value of ',(0,i.yg)("inlineCode",{parentName:"p"},"var"),".\nBut this is up to the scheduler and is non-deterministic.\nSuch undefined behaviours can cripple the execution of a program if ",(0,i.yg)("inlineCode",{parentName:"p"},"var")," is some critical variable."),(0,i.yg)("p",null,"Let's see this bug in action.\nGo to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/synchronization/drills/tasks/race-condition/support/c/race_condition.c"),", compile and run the code a few times.\nIt spawns to threads that do exactly what we've talked about so far: one thread increments ",(0,i.yg)("inlineCode",{parentName:"p"},"var")," 10 million times, while the other decrements it 10 million times."),(0,i.yg)("p",null,"As you can see from running the program, the differences between subsequent runs can be substantial.\nTo fix this, we must ensure that ",(0,i.yg)("strong",{parentName:"p"},"only one thread")," can execute either ",(0,i.yg)("inlineCode",{parentName:"p"},"var++")," or ",(0,i.yg)("inlineCode",{parentName:"p"},"var--")," at any time.\nWe call these code sections ",(0,i.yg)("strong",{parentName:"p"},"critical sections"),".\nA critical section is a piece of code that can only be executed by ",(0,i.yg)("strong",{parentName:"p"},"one thread")," at a time.\nSo we need some sort of ",(0,i.yg)("em",{parentName:"p"},"mutual exclusion mechanism")," so that when one thread runs the critical section, the other has to ",(0,i.yg)("strong",{parentName:"p"},"wait")," before entering it.\nThis mechanism is called a ",(0,i.yg)("strong",{parentName:"p"},"mutex"),', whose name comes from "mutual exclusion".'),(0,i.yg)("h3",{id:"thread-local-storage-tls"},"Thread-Local Storage (TLS)"),(0,i.yg)("p",null,"First things first: what if we don't want data to be shared between threads?\nAre we condemned to have to worry about race conditions?\nWell, no."),(0,i.yg)("p",null,'To protect data from race conditions "by design", we can place in what\'s called ',(0,i.yg)("strong",{parentName:"p"},"Thread-Local Storage (TLS)"),'.\nAs its name implies, this is a type of storage that is "owned" by individual threads, as opposed to being shared among all threads.\n',(0,i.yg)("strong",{parentName:"p"},"Do not confuse it with copy-on-write"),".\nTLS pages are always duplicated when creating a new thread and their contents are reinitialised."),(0,i.yg)("h2",{id:"user-level-threads"},"User-Level Threads"),(0,i.yg)("p",null,"User-level threads differ from the threads you are used to (kernel-level threads, those created by ",(0,i.yg)("inlineCode",{parentName:"p"},"pthread_create"),").\nThis kind of threads are scheduled by an user-level scheduler, and can run on the same kernel-level thread.\nFrom now on, we will refer to user-level threads as fibers, and kernel-level threads as simply threads."),(0,i.yg)("p",null,"We will use the fiber implementation from ",(0,i.yg)("inlineCode",{parentName:"p"},"libboost"),".\nThis implementation uses a cooperative scheduler on each thread, meaning that each fiber has to yield, in order for other fiber to be executed.\nWe will also use C++, and the standard ",(0,i.yg)("inlineCode",{parentName:"p"},"thread")," implementation."),(0,i.yg)("h3",{id:"prerequisites"},"Prerequisites"),(0,i.yg)("p",null,"Unless you are using the OS docker image, you will need to install ",(0,i.yg)("inlineCode",{parentName:"p"},"cmake")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"libboost"),".\nYou can do this with the following command:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-console"},"student@os:~$ sudo apt-get install cmake libboost-context-dev libboost-fiber-dev\n")),(0,i.yg)("h3",{id:"creation"},"Creation"),(0,i.yg)("p",null,"Follow the ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/user-level-threads/guides/user-level-threads/support/simple.cc")," implementation.\nIt creates ",(0,i.yg)("inlineCode",{parentName:"p"},"NUM_FIBERS"),' fibers, that each prints "Hello World".\nTo compile and run the program, do the following steps:'),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-console"},"student@os:~/.../user-level-threads/support$ mkdir build/\nstudent@os:~/.../user-level-threads/support$ cd build/\nstudent@os:~/.../user-level-threads/support$ cmake -S .. -B .\nstudent@os:~/.../user-level-threads/support$ make\nstudent@os:~/.../user-level-threads/support$ ./simple\n")),(0,i.yg)("p",null,"The ",(0,i.yg)("inlineCode",{parentName:"p"},"cmake")," step must be executed only once.\nAfter modifying the source files, it is enough to run ",(0,i.yg)("inlineCode",{parentName:"p"},"make"),"."),(0,i.yg)("h4",{id:"practice-sleeper-fiber"},"Practice: Sleeper Fiber"),(0,i.yg)("p",null,"Add in ",(0,i.yg)("inlineCode",{parentName:"p"},"user-level-threads/support/simple.cc")," a fiber that sleeps for 5 seconds, before the other ones are created.\nWhat happens?\nAnswer in this ",(0,i.yg)("a",{parentName:"p",href:"questions/sleeping-on-a-fiber.md"},"quiz"),"."),(0,i.yg)("h3",{id:"no-system-calls"},"No system calls"),(0,i.yg)("p",null,"Use ",(0,i.yg)("inlineCode",{parentName:"p"},"strace")," to find calls to ",(0,i.yg)("inlineCode",{parentName:"p"},"clone()")," in the execution of ",(0,i.yg)("inlineCode",{parentName:"p"},"simple"),".\nCan you find any?\nProvide your answer in this ",(0,i.yg)("a",{parentName:"p",href:"questions/fiber-strace.md"},"quiz"),"\n",(0,i.yg)("inlineCode",{parentName:"p"},"clone")," is the system call used to create ",(0,i.yg)("strong",{parentName:"p"},"kernel-level")," threads, as pointed out ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/Compute/lab6#guide-threads-and-processes-clone"},"in this guide on creating threads and processes"),"."),(0,i.yg)("h3",{id:"synchronization-1"},"Synchronization"),(0,i.yg)("p",null,"By default, the fibers that run on the same thread are synchronized - no race-conditions can occur.\nThis is illustrated by the ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/user-level-threads/guides/user-level-threads/support/sum.cc")," implementation."),(0,i.yg)("p",null,"The user can, however, implement further synchronization, by using the ",(0,i.yg)("inlineCode",{parentName:"p"},"yield()")," call, or classic synchronization methods, like mutexes, barriers and condition variables."),(0,i.yg)("h4",{id:"yielding"},"Yielding"),(0,i.yg)("p",null,"As the scheduler is cooperative, each fiber can yield (or not), to allow another fiber to run.\nFollow the ",(0,i.yg)("inlineCode",{parentName:"p"},"compute/user-level-threads/guides/user-level-threads/support/yield_launch.cc")," implementation and run it.\nNote the ",(0,i.yg)("inlineCode",{parentName:"p"},"boost::fibers::launch::dispatch")," parameter provided to the fiber constructor.\nIt notifies the scheduler to start the fiber as soon as it is created.\nIn order to explain the output, we must consider that the fibers are created by a ",(0,i.yg)("strong",{parentName:"p"},"main fiber"),", that is scheduled along with the others, in this case."),(0,i.yg)("h5",{id:"practice"},"Practice"),(0,i.yg)("p",null,"Modify the launch parameter into ",(0,i.yg)("inlineCode",{parentName:"p"},"boost::fibers::launch::post"),", compile and notice the differences.\nThe ",(0,i.yg)("inlineCode",{parentName:"p"},"post")," parameter notifies the scheduler not to start the fibers immediately, but rather place them into an execution queue.\nTheir execution will start after the main fiber calls the ",(0,i.yg)("inlineCode",{parentName:"p"},"join()")," function."),(0,i.yg)("h4",{id:"barriers"},"Barriers"),(0,i.yg)("p",null,"Follow the ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/user-level-threads/guides/user-level-threads/support/yield_barrier.cc")," implementation.\nIt uses a barrier to achieve the same result as the previous implementation, that used ",(0,i.yg)("inlineCode",{parentName:"p"},"post")," as the launch parameter."),(0,i.yg)("h4",{id:"c-unique_lock"},"C++ unique_lock"),(0,i.yg)("p",null,(0,i.yg)("inlineCode",{parentName:"p"},"unique_lock")," is a type of mutex that is unlocked automatically when the end of its scope is reached (end of function or bracket-pair)."),(0,i.yg)("h2",{id:"scheduling"},"Scheduling"),(0,i.yg)("p",null,"Up to now, we know that the OS decides which ",(0,i.yg)("strong",{parentName:"p"},"thread")," (not process) runs on each CPU core at each time.\nNow we'll learn about the component that performs this task specifically: ",(0,i.yg)("strong",{parentName:"p"},"the scheduler"),"."),(0,i.yg)("p",null,"There are thousands of threads running at any time in a modern OS.\nThe job of the scheduler is to run and pause threads as well as allocate them to the CPU cores, with the following goals:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"fairness"),": we do want all threads to get the same chance to run, i.e. run for about the same amount of time"),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"throughput"),": we want to run as many threads to completion so as to complete as many tasks as we can")),(0,i.yg)("p",null,"To do this, the scheduler must decide, at given times, to suspend a thread, save its current state and let another one run in its place.\nThis event is called a ",(0,i.yg)("strong",{parentName:"p"},"context switch"),".\nA context switch means changing the state of one thread (the replaced thread) from RUNNING to WAITING, and the state of the replacement thread from READY / WAITING to RUNNING."),(0,i.yg)("h3",{id:"user-level-vs-kernel-level-threads"},"User-Level vs Kernel-Level Threads"),(0,i.yg)("p",null,"There are two types of threads.\nThe threads you've used so far are ",(0,i.yg)("strong",{parentName:"p"},"kernel-level threads (KLT)"),".\nThey are created and scheduled in the kernel of the OS.\nOne of the most important of their features is that they offer true parallelism.\nWith KLTs, we can truly run a program on all the cores of our CPU at once.\nBut we must pay a price for this: scheduling them is very complex, and context switches are costly (in terms of time), especially when switching threads belonging to different processes."),(0,i.yg)("p",null,"By contrast, ",(0,i.yg)("strong",{parentName:"p"},"user-level threads (ULT)")," are managed by the user space.\nMore of the ULTs created by a program are generally mapped to the same kernel thread.\nIf a process only creates ULTs, then they will all be mapped to the single, main kernel thread of the process.\nSo if we cannot run code in parallel with ULTs, then why use them?\nWell, programs that create many context switches may suffer from the larger overhead if they use kernel-level threads.\nIn such cases, user-level threads may be useful as context switches bring less overhead between user-level threads."),(0,i.yg)("h3",{id:"thread-control-block"},"Thread Control Block"),(0,i.yg)("p",null,"Let's dissect the ",(0,i.yg)("inlineCode",{parentName:"p"},"threads_create()")," function a bit.\nIt first initialises its queues and the timer for preemption.\nWe'll discuss preemption separately, in a ",(0,i.yg)("a",{parentName:"p",href:"#scheduling---how-is-it-done"},"section of its own"),".\nAfter performing initialisations, the function creates a ",(0,i.yg)("inlineCode",{parentName:"p"},"TCB")," object.\nTCB stands for ",(0,i.yg)("strong",{parentName:"p"},"Thread Control Block"),"."),(0,i.yg)("p",null,"During the lecture, you saw that the kernel stores one instance of a ",(0,i.yg)("a",{parentName:"p",href:"https://elixir.bootlin.com/linux/v5.19.11/source/include/linux/sched.h#L726"},(0,i.yg)("inlineCode",{parentName:"a"},"task_struct"))," for each thread.\nRemember that its most important fields are:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-c"},"struct task_struct {\n unsigned int                    __state;\n\n void                           *stack;\n\n unsigned int                    flags;\n\n int                             on_cpu;\n int                             prio;\n\n /* Scheduler information */\n struct sched_entity             se;\n const struct sched_class        *sched_class;\n\n /* The VAS: memory mappings */\n struct mm_struct                *mm;\n\n int                             exit_state;\n int                             exit_code;\n\n pid_t                           pid;\n\n struct task_struct __rcu        *parent;\n\n /* Child processes */\n struct list_head                children;\n\n /* Open file information */\n struct files_struct             *files;\n};\n")),(0,i.yg)("p",null,"As you can see, this ",(0,i.yg)("inlineCode",{parentName:"p"},"struct")," stores ",(0,i.yg)("em",{parentName:"p"},"metadata")," regarding a given thread.\nThe same is true about the ",(0,i.yg)("inlineCode",{parentName:"p"},"TCB")," in ",(0,i.yg)("inlineCode",{parentName:"p"},"libult.so"),":"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-c"},"typedef struct {\n int id;\n ucontext_t context;\n bool has_dynamic_stack;\n void *(*start_routine) (void *);\n void *argument;\n void *return_value;\n} TCB;\n")),(0,i.yg)("p",null,"It stores the thread ID (tid - ",(0,i.yg)("inlineCode",{parentName:"p"},"id"),"), similar to the PID of a process.\nIt stores a pointer to the function passed as argument to ",(0,i.yg)("inlineCode",{parentName:"p"},"threads_create()")," (",(0,i.yg)("inlineCode",{parentName:"p"},"start_routine"),"), as well as the argument (",(0,i.yg)("inlineCode",{parentName:"p"},"argument"),") and the returned value (",(0,i.yg)("inlineCode",{parentName:"p"},"return_value"),") of said function."),(0,i.yg)("p",null,"In addition, the ",(0,i.yg)("inlineCode",{parentName:"p"},"TCB")," stores a ",(0,i.yg)("inlineCode",{parentName:"p"},"context"),".\nFrom the ",(0,i.yg)("a",{parentName:"p",href:"https://pubs.opengroup.org/onlinepubs/7908799/xsh/ucontext.h.html"},"man page of the ",(0,i.yg)("inlineCode",{parentName:"a"},"ucontext.h")," header"),", we can see this type is a ",(0,i.yg)("inlineCode",{parentName:"p"},"struct")," that stores a pointer to the stack of the current thread (",(0,i.yg)("inlineCode",{parentName:"p"},"uc_stack"),").\nThis is similar to the ",(0,i.yg)("inlineCode",{parentName:"p"},"stack")," pointer in the ",(0,i.yg)("inlineCode",{parentName:"p"},"task_struct")," above.\nIn short, we can say a context defines an execution unit, such as a thread.\n",(0,i.yg)("strong",{parentName:"p"},"This is why changing the running thread is called a context switch.")),(0,i.yg)("p",null,"Let's compare this context with another thread implementation, from ",(0,i.yg)("a",{parentName:"p",href:"https://unikraft.org/"},"Unikraft"),".\nWe'll look at the ",(0,i.yg)("a",{parentName:"p",href:"https://github.com/unikraft/unikraft/blob/9bf6e63314a401204c02597834fb02f63a29aaf4/lib/uksched/include/uk/thread.h#L55-L76"},(0,i.yg)("inlineCode",{parentName:"a"},"uk_thread"))," ",(0,i.yg)("inlineCode",{parentName:"p"},"struct"),", which is the TCB used in Unikraft:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-c"},"struct uk_thread {\n const char *name;\n void *stack;\n void *tls;\n void *ctx;\n UK_TAILQ_ENTRY(struct uk_thread) thread_list;\n uint32_t flags;\n __snsec wakeup_time;\n bool detached;\n struct uk_waitq waiting_threads;\n struct uk_sched *sched;\n void (*entry)(void *);\n void *arg;\n void *prv;\n};\n")),(0,i.yg)("p",null,"There are some visible similarities between the two TCBs."),(0,i.yg)("iframe",{id:"5aa8131b-1c86-4b45-8d24-23f1721586d9",srcdoc:'<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"><\/script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"><\/script><script>hljs.highlightAll();<\/script><div class="card d-flex" style="width: 75%; margin: auto; margin-top: 1rem; margin-bottom: 1rem;"> <div class="card-header" id="69693a83-662f-40a3-af88-d218f3a7f220"> <p>Which members of the TCBs in <code>libult</code> and Unikraft have similar meanings?</p> </div> <ul class="list-group list-group-flush"> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="a91e2cbc-c869-4c72-ab56-1e094af71c16"> <label class="form-check-label" for="a91e2cbc-c869-4c72-ab56-1e094af71c16"> <p><code>return_value</code> and <code>prv</code></p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="5ca39122-40cf-4fa9-8301-cdcfecd60980"> <label class="form-check-label" for="5ca39122-40cf-4fa9-8301-cdcfecd60980"> <p><code>context</code> and <code>ctx</code></p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="5b011322-439e-44ab-a3c5-5e9ac27d1bf7"> <label class="form-check-label" for="5b011322-439e-44ab-a3c5-5e9ac27d1bf7"> <p><code>arguments</code> and <code>flags</code></p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="1682687a-034c-491e-b4ee-4425d0749ace"> <label class="form-check-label" for="1682687a-034c-491e-b4ee-4425d0749ace"> <p><code>context.uc_stack</code> and <code>stack</code></p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="5eb389af-f0dd-4a99-8869-8092ec65baa5"> <label class="form-check-label" for="5eb389af-f0dd-4a99-8869-8092ec65baa5"> <p><code>context</code> and <code>tls</code></p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="f9d8f1ec-d1a0-491b-a5f3-f45bf31a2f7d"> <label class="form-check-label" for="f9d8f1ec-d1a0-491b-a5f3-f45bf31a2f7d"> <p><code>context</code> and <code>sched</code></p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="54617b9e-92b8-4374-bec2-0d3cf9eabbee"> <label class="form-check-label" for="54617b9e-92b8-4374-bec2-0d3cf9eabbee"> <p><code>start_routine</code> and <code>entry</code></p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="277ef745-f830-416c-a5e1-de81b81b4ec4"> <label class="form-check-label" for="277ef745-f830-416c-a5e1-de81b81b4ec4"> <p><code>id</code> and <code>name</code></p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="3d6e4169-45c6-4cf3-bf7c-2dd941e7d163"> <label class="form-check-label" for="3d6e4169-45c6-4cf3-bf7c-2dd941e7d163"> <p><code>argument</code> and <code>arg</code></p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="bd6a3f91-f4cd-4ee1-bcfc-8e2b8822ab89"> <label class="form-check-label" for="bd6a3f91-f4cd-4ee1-bcfc-8e2b8822ab89"> <p><code>has_dynamic_stack</code> and <code>detached</code></p> </label> </div> </li> </ul> <div class="card-footer"> <div class="text-center" style="padding: 5px;"> <button class="check btn btn-primary" type="button" onclick="console.log(\'Clickedcheck\');answerIndex=\'54617b9e-92b8-4374-bec2-0d3cf9eabbee\';document.getElementsByClassName(\'check\')[0].classList.add(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=true;if(radio.checked){if(radio.id===answerIndex){choices[i].classList.add(\'list-group-item-success\');document.getElementsByClassName(\'feedback\')[0].classList.remove(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'feedback\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;}else{choices[i].classList.add(\'list-group-item-danger\');}}}">Check Answer </button> <button class="reset btn btn-default" type="button" onclick="console.log(\'Clickedreset\');document.getElementsByClassName(\'check\')[0].classList.remove(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=false;choices[i].classList.remove(\'list-group-item-success\');choices[i].classList.remove(\'list-group-item-danger\');radio.checked=false;}document.getElementsByClassName(\'feedback\')[0].classList.add(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'card\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;">Try Again</button> </div> </div></div><div class="feedback card d-flex d-none" style="width: 80%; margin: auto; margin-top: 1rem;"> <div class="card-header"> Feedback </div> <div class="card-body alert alert-success"> <p><code>start_routine</code> and <code>entry</code> are the functions that run in the newly created threads.<code>context.uc_stack</code> and <code>stack</code> are pointers to the stack of the newly created threads.<code>argument</code> and <code>arg</code> are pointers to the arguments of <code>start_routine</code> and <code>entry</code>, respectively.<code>context</code> and <code>ctx</code> are the contexts in which the new threads run.<code>return_value</code> and <code>prv</code> are both pointers to the values returned by the thread functions.</p> </div></div>',width:"100%",style:{border:"none",overflow:"hidden"},onLoad:()=>{var e=document.getElementById("5aa8131b-1c86-4b45-8d24-23f1721586d9");e.height=e.contentWindow.document.body.scrollHeight+36}}),(0,i.yg)("p",null,"Therefore, the workflow for creating and running a thread goes like this:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-console"},"main thread\n    |\n    `--\x3e threads_create()\n            |\n     |--\x3e tcb_new()\n            `--\x3e makecontext()\n             |\n      `--\x3e handle_thread_start() - called using the context\n              |\n       |--\x3e start_routine() - the thread runs\n                            `--\x3e threads_exit()\n")),(0,i.yg)("p",null,"Compile and run the code in ",(0,i.yg)("inlineCode",{parentName:"p"},"libult/support/test_ult.c"),".\nIf you encounter the following error when running ",(0,i.yg)("inlineCode",{parentName:"p"},"test_ult"),", remember what you learned about the loader and using custom shared libraries in the ",(0,i.yg)("a",{parentName:"p",href:"lab2.md#libraries-and-libc"},"Software Stack lab"),"."),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-console"},"./test_ult: error while loading shared libraries: libult.so: cannot open shared object file: No such file or directory\n")),(0,i.yg)("blockquote",null,(0,i.yg)("p",{parentName:"blockquote"},"Hint: Use the ",(0,i.yg)("inlineCode",{parentName:"p"},"LD_LIBRARY_PATH")," variable.")),(0,i.yg)("p",null,"Notice that the threads run their code and alternatively, because their prints appear interleaved."),(0,i.yg)("p",null,(0,i.yg)("a",{parentName:"p",href:"questions/ult-thread-ids.md"},"Quiz")),(0,i.yg)("h3",{id:"scheduling---how-is-it-done"},"Scheduling - How is it done?"),(0,i.yg)("p",null,"There are two types of schedulers: ",(0,i.yg)("strong",{parentName:"p"},"preemptive")," and ",(0,i.yg)("strong",{parentName:"p"},"cooperative"),".\nWhen discussing this distinction, we need to first define the notion of ",(0,i.yg)("strong",{parentName:"p"},"yielding"),".\nYielding the CPU means that a thread suspends its own execution and enters the WAITING or READY state, either as a result of a blocking call (I/O operations or calling the scheduler's ",(0,i.yg)("inlineCode",{parentName:"p"},"yield()")," function directly).\nSo, yielding the CPU triggers a context switch whereby the current thread stops running and another one resumes or starts running in its place."),(0,i.yg)("h4",{id:"cooperative-scheduling"},"Cooperative Scheduling"),(0,i.yg)("p",null,"Cooperative scheduling relies on the fact that threads themselves would yield the CPU at some point.\nIf threads don't abide by this convention, they end up monopolising the CPU (since there is no one to suspend them) and end up starving the others.\nYou can get a feel of this behaviour by running the cooperative ",(0,i.yg)("a",{parentName:"p",href:"https://github.com/unikraft/unikraft/blob/staging/lib/ukschedcoop/schedcoop.c"},"scheduler from Unikraft")," in the ","[lecture demos]","."),(0,i.yg)("p",null,'This type of schedulers have the advantage of being lightweight, thus resulting in less overhead caused by context switches.\nHowever, as we\'ve already stated, they rely on the "good will" of threads to yield the CPU at some point.'),(0,i.yg)("h4",{id:"preemptive-scheduling"},"Preemptive Scheduling"),(0,i.yg)("p",null,"Preemptive scheduling solves the issue stated above by leaving the task of suspending the currently RUNNING thread and replacing it with another one from the READY queue up to the scheduler.\nThis increases its complexity and the duration of context switches, but threads now are not required to worry about yielding themselves and can focus on running their code and performing the task for which they are created."),(0,i.yg)("p",null,"Preemptive schedulers allow threads to run only for a maximum amount of time, called a ",(0,i.yg)("strong",{parentName:"p"},"time slice")," (usually a few milliseconds).\nThey use timers which fire when a new time slice passes.\nThe firing of one such timer causes a context switch whereby the currently RUNNING thread is ",(0,i.yg)("em",{parentName:"p"},"preempted")," (i.e. suspended) and replaced with another one."),(0,i.yg)("iframe",{id:"9cb306b8-960b-4baa-8326-0fa0ed9e194a",srcdoc:'<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"><\/script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"><\/script><script>hljs.highlightAll();<\/script><div class="card d-flex" style="width: 75%; margin: auto; margin-top: 1rem; margin-bottom: 1rem;"> <div class="card-header" id="3dec95ee-ffb5-4e83-936d-79f2f98c0c40"> <p>Inspect the code in <code>support/libult/threads.c</code> further.\nWhich type of scheduler does <code>libult.so</code> use?</p> </div> <ul class="list-group list-group-flush"> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="965d1134-1765-435e-8db2-0638edc54675"> <label class="form-check-label" for="965d1134-1765-435e-8db2-0638edc54675"> <p>It uses both a cooperative and a preemptive scheduler</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="819f400a-e545-4fce-9a86-6a2bc5463050"> <label class="form-check-label" for="819f400a-e545-4fce-9a86-6a2bc5463050"> <p>It uses a cooperative scheduler</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="97c3efb0-11c8-4bb4-b2ef-5a95de01424f"> <label class="form-check-label" for="97c3efb0-11c8-4bb4-b2ef-5a95de01424f"> <p>It uses a preemptive scheduler</p> </label> </div> </li> </ul> <div class="card-footer"> <div class="text-center" style="padding: 5px;"> <button class="check btn btn-primary" type="button" onclick="console.log(\'Clickedcheck\');answerIndex=\'97c3efb0-11c8-4bb4-b2ef-5a95de01424f\';document.getElementsByClassName(\'check\')[0].classList.add(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=true;if(radio.checked){if(radio.id===answerIndex){choices[i].classList.add(\'list-group-item-success\');document.getElementsByClassName(\'feedback\')[0].classList.remove(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'feedback\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;}else{choices[i].classList.add(\'list-group-item-danger\');}}}">Check Answer </button> <button class="reset btn btn-default" type="button" onclick="console.log(\'Clickedreset\');document.getElementsByClassName(\'check\')[0].classList.remove(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=false;choices[i].classList.remove(\'list-group-item-success\');choices[i].classList.remove(\'list-group-item-danger\');radio.checked=false;}document.getElementsByClassName(\'feedback\')[0].classList.add(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'card\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;">Try Again</button> </div> </div></div><div class="feedback card d-flex d-none" style="width: 80%; margin: auto; margin-top: 1rem;"> <div class="card-header"> Feedback </div> <div class="card-body alert alert-success"> <p><code>libult.so</code> uses a preemptive scheduler.\nIts timer is initialised in the <code>init_profiling_timer()</code> function.\nThe context switch is performed in the <code>handle_sigprof()</code> function.</p> </div></div>',width:"100%",style:{border:"none",overflow:"hidden"},onLoad:()=>{var e=document.getElementById("9cb306b8-960b-4baa-8326-0fa0ed9e194a");e.height=e.contentWindow.document.body.scrollHeight+36}}),(0,i.yg)("p",null,"Look at the ",(0,i.yg)("inlineCode",{parentName:"p"},"init_profiling_timer()")," function.\nIt creates a timer that generates a ",(0,i.yg)("inlineCode",{parentName:"p"},"SIGPROF")," signal and then defines a handler (the ",(0,i.yg)("inlineCode",{parentName:"p"},"handle_sigprof()")," function) that is executed whenever the ",(0,i.yg)("inlineCode",{parentName:"p"},"SIGPROF")," signal is received."),(0,i.yg)("iframe",{id:"ae421bc8-f57f-4c7d-b60a-4d7dd96ae1c3",srcdoc:'<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"><\/script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"><\/script><script>hljs.highlightAll();<\/script><div class="card d-flex" style="width: 75%; margin: auto; margin-top: 1rem; margin-bottom: 1rem;"> <div class="card-header" id="6720dae1-a579-4439-b4ee-186e91850a91"> <p>Using the <a href="https://man7.org/linux/man-pages/man2/setitimer.2.html">man page</a>, what is the time slice used by the scheduler in <code>libult.so</code>?</p> </div> <ul class="list-group list-group-flush"> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="81a8561c-3650-4416-95fa-89d0df86e58a"> <label class="form-check-label" for="81a8561c-3650-4416-95fa-89d0df86e58a"> <p>100 milliseconds</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="6bfa2b7c-6ae7-4dd1-aee5-8c84c596bd51"> <label class="form-check-label" for="6bfa2b7c-6ae7-4dd1-aee5-8c84c596bd51"> <p>10 microseconds</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="36ab39fd-acc6-4f18-81de-16caf6b85604"> <label class="form-check-label" for="36ab39fd-acc6-4f18-81de-16caf6b85604"> <p>10 milliseconds</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="6f22b1f6-14fe-4846-8ca2-26824cf8f95e"> <label class="form-check-label" for="6f22b1f6-14fe-4846-8ca2-26824cf8f95e"> <p>100 microseconds</p> </label> </div> </li> </ul> <div class="card-footer"> <div class="text-center" style="padding: 5px;"> <button class="check btn btn-primary" type="button" onclick="console.log(\'Clickedcheck\');answerIndex=\'36ab39fd-acc6-4f18-81de-16caf6b85604\';document.getElementsByClassName(\'check\')[0].classList.add(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=true;if(radio.checked){if(radio.id===answerIndex){choices[i].classList.add(\'list-group-item-success\');document.getElementsByClassName(\'feedback\')[0].classList.remove(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'feedback\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;}else{choices[i].classList.add(\'list-group-item-danger\');}}}">Check Answer </button> <button class="reset btn btn-default" type="button" onclick="console.log(\'Clickedreset\');document.getElementsByClassName(\'check\')[0].classList.remove(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=false;choices[i].classList.remove(\'list-group-item-success\');choices[i].classList.remove(\'list-group-item-danger\');radio.checked=false;}document.getElementsByClassName(\'feedback\')[0].classList.add(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'card\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;">Try Again</button> </div> </div></div><div class="feedback card d-flex d-none" style="width: 80%; margin: auto; margin-top: 1rem;"> <div class="card-header"> Feedback </div> <div class="card-body alert alert-success"> <p>The code we\'re interested in lies in the function <code>init_profiling_timer()</code>:</p><pre><code class="language-c">const struct itimerval timer = { { 0, 10000 }, { 0, 1 }  // arms the timer as soon as possible\n};</code></pre><p>The <a href="https://man7.org/linux/man-pages/man2/setitimer.2.html">man page</a> gives the following definition the <code>struct itimerval</code>:</p><pre><code class="language-c">struct itimerval { struct timeval it_interval; /* Interval for periodic timer */ struct timeval it_value;    /* Time until next expiration */\n};<br />struct timeval { time_t      tv_sec;         /* seconds */ suseconds_t tv_usec;        /* microseconds */\n};</code></pre><p>So when constructing the <code>timer</code> variable, <code>{ 0, 10000 }</code> means 0 seconds and 10000 microseconds, i.e. 0 seconds and 10 milliseconds.</p> </div></div>',width:"100%",style:{border:"none",overflow:"hidden"},onLoad:()=>{var e=document.getElementById("ae421bc8-f57f-4c7d-b60a-4d7dd96ae1c3");e.height=e.contentWindow.document.body.scrollHeight+36}}),(0,i.yg)("p",null,"It is this handler that performs the context switch per se.\nLook at its code.\nIt first saves the context of the current thread:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-c"},"ucontext_t *stored = &running->context;\nucontext_t *updated = (ucontext_t *) context;\n\nstored->uc_flags = updated->uc_flags;\nstored->uc_link = updated->uc_link;\nstored->uc_mcontext = updated->uc_mcontext;\nstored->uc_sigmask = updated->uc_sigmask;\n")),(0,i.yg)("p",null,"Then it places the current thread in the ",(0,i.yg)("inlineCode",{parentName:"p"},"ready")," queue and replaces it with the first thread in the same queue.\nThis algorithm (that schedules the first thread in the READY queue) is called ",(0,i.yg)("em",{parentName:"p"},"Round-Robin"),":"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-c"},"if (queue_enqueue(ready, running) != 0) {\n abort();\n}\n\nif ((running = queue_dequeue(ready)) == NULL) {\n abort();\n}\n")),(0,i.yg)("p",null,"The new ",(0,i.yg)("inlineCode",{parentName:"p"},"running")," thread is resumed upon setting the current context to it:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-c"},"if (setcontext(&running->context) == -1) {\n abort();\n}\n")),(0,i.yg)("p",null,"This is how scheduling is done!"),(0,i.yg)("h2",{id:"guide-interaction-between-threads-and-fibers"},"Guide: Interaction Between Threads and Fibers"),(0,i.yg)("p",null,"As we mentioned before, multiple fibers can run on the same thread, and a scheduler is implemented on each thread.\nBy default, the scheduling algorithm is ",(0,i.yg)("a",{parentName:"p",href:"https://www.guru99.com/round-robin-scheduling-example.html"},(0,i.yg)("inlineCode",{parentName:"a"},"round_robin")),".\nIt runs the fibers, in the order of their creation, until they yield or finish their work.\nIf a fiber yields, it is placed at the back of the round-robin queue.\nUsing this scheduler, each thread only uses its fibers;\nif one thread has more work to do than another, bad luck.\nThis may lead to starvation."),(0,i.yg)("p",null,"But there are other scheduler implementations, such as ",(0,i.yg)("inlineCode",{parentName:"p"},"shared_work")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"work_stealing"),".\nFollow the ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/user-level-threads/guides/user-level-threads/support/threads_and_fibers.cc")," implementation.\nIt creates multiple fibers and threads, and uses the ",(0,i.yg)("inlineCode",{parentName:"p"},"shared_work")," scheduler to balance the workload between the threads.\nEach main fiber, from each thread, is suspended until all worker fibers have completed their work, using a condition variable."),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-cpp"},"cnd_count.wait( lk, []{ return 0 == fiber_count; } );\n")),(0,i.yg)("p",null,"The program also uses ",(0,i.yg)("inlineCode",{parentName:"p"},"thread local storage")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"fiber local storage")," to store the ID of each thread / fiber."),(0,i.yg)("p",null,"Now change the ",(0,i.yg)("inlineCode",{parentName:"p"},"shared_work")," scheduler into the ",(0,i.yg)("inlineCode",{parentName:"p"},"work_stealing")," one.\nIt takes a parameter, the number of threads that will use that scheduler."),(0,i.yg)("p",null,"Compile, rerun and note the differences.\nThe ",(0,i.yg)("inlineCode",{parentName:"p"},"work_stealing"),' scheduler, as the name suggests, will "steal" fibers from other schedulers.\nSo, if the ',(0,i.yg)("inlineCode",{parentName:"p"},"shared_work")," scheduler tried to balance the available work between the available threads, the ",(0,i.yg)("inlineCode",{parentName:"p"},"work_stealing")," one will focus on having as many threads as possible on 100% workload.\nVary the number of threads and fibers, and the workload (maybe put each fibre to do some computational-intensive work), and observe the results."),(0,i.yg)("h2",{id:"guide-user-level-threads-scheduler"},"Guide: User-Level Threads Scheduler"),(0,i.yg)("p",null,"Go to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/scheduling/guides/libult/support"),".\nIt contains a minimalist ",(0,i.yg)("strong",{parentName:"p"},"user-level threads")," scheduler.\nCompiling it produces a shared library called ",(0,i.yg)("inlineCode",{parentName:"p"},"libult.so"),".\nYou can also consult its ",(0,i.yg)("a",{parentName:"p",href:"https://www.schaertl.me/posts/a-bare-bones-user-level-thread-library/"},"documentation"),".\nIt explains the API as well as its implementation.\nThe API exposed by the scheduling library is very simple.\nIt is only made up of 3 functions:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"threads_create()")," creates a new ULT"),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"threads_exit()")," moves the current ULT to the COMPLETED state"),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"threads_join()")," waits for a given thread to end and saves its return value in the ",(0,i.yg)("inlineCode",{parentName:"li"},"result")," argument")),(0,i.yg)("p",null,"Look inside ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/compute/scheduling/guides/libult/support/threads.c"),".\nHere you will find the 3 functions mentioned above."),(0,i.yg)("p",null,"The scheduler only uses 3 states: RUNNING, READY, COMPLETED."),(0,i.yg)("iframe",{id:"74538414-53bd-4fc4-ab27-9caa8f6683f2",srcdoc:'<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"><\/script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"><\/script><script>hljs.highlightAll();<\/script><div class="card d-flex" style="width: 75%; margin: auto; margin-top: 1rem; margin-bottom: 1rem;"> <div class="card-header" id="a7736388-43dd-4b39-8d6d-74f8db090444"> <p>How many threads can be RUNNING simultaneously if we only create them using the API exposed by <code>libult.so</code>?</p> </div> <ul class="list-group list-group-flush"> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="36330cf4-934a-4208-8797-34bb01f64311"> <label class="form-check-label" for="36330cf4-934a-4208-8797-34bb01f64311"> <p>None</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="a422d2e0-b005-49f7-9381-d1fed5038fae"> <label class="form-check-label" for="a422d2e0-b005-49f7-9381-d1fed5038fae"> <p>1</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="4dd6204e-f83f-4e09-ab2d-5f5cdba71282"> <label class="form-check-label" for="4dd6204e-f83f-4e09-ab2d-5f5cdba71282"> <p>2: the main thread and another one for the created threads</p> </label> </div> </li> <li class="list-group-item choice"> <div class="form-check"> <input class="form-check-input" type="radio" name="flexRadioDefault" id="88170272-4ca8-4a19-9af5-3bf2112fef08"> <label class="form-check-label" for="88170272-4ca8-4a19-9af5-3bf2112fef08"> <p>Equal to the number of cores on the CPU</p> </label> </div> </li> </ul> <div class="card-footer"> <div class="text-center" style="padding: 5px;"> <button class="check btn btn-primary" type="button" onclick="console.log(\'Clickedcheck\');answerIndex=\'a422d2e0-b005-49f7-9381-d1fed5038fae\';document.getElementsByClassName(\'check\')[0].classList.add(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=true;if(radio.checked){if(radio.id===answerIndex){choices[i].classList.add(\'list-group-item-success\');document.getElementsByClassName(\'feedback\')[0].classList.remove(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'feedback\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;}else{choices[i].classList.add(\'list-group-item-danger\');}}}">Check Answer </button> <button class="reset btn btn-default" type="button" onclick="console.log(\'Clickedreset\');document.getElementsByClassName(\'check\')[0].classList.remove(\'disabled\');choices=document.getElementsByClassName(\'choice\');for(i=0;i<choices.length;i++){radio=choices[i].firstElementChild.firstElementChild;radio.disabled=false;choices[i].classList.remove(\'list-group-item-success\');choices[i].classList.remove(\'list-group-item-danger\');radio.checked=false;}document.getElementsByClassName(\'feedback\')[0].classList.add(\'d-none\');var savTop=parent.document.documentElement.scrollTop;document.getElementsByClassName(\'card\')[0].scrollIntoView(false);parent.document.documentElement.scrollTop=savTop;">Try Again</button> </div> </div></div><div class="feedback card d-flex d-none" style="width: 80%; margin: auto; margin-top: 1rem;"> <div class="card-header"> Feedback </div> <div class="card-body alert alert-success"> <p>Only kernel-level threads can run in parallel.\nSince all <code>libult.so</code> threads are user-level threads, they run within the same kernel-level thread, so only one of them can run at any time.</p> </div></div>',width:"100%",style:{border:"none",overflow:"hidden"},onLoad:()=>{var e=document.getElementById("74538414-53bd-4fc4-ab27-9caa8f6683f2");e.height=e.contentWindow.document.body.scrollHeight+36}}),(0,i.yg)("p",null,"The threads in the READY and COMPLETED states are kept in 2 separate queues.\nWhen the scheduler wants to run a new thread, it retrieves it from the READY queue.\nWhen a thread ends its execution, it is added to the COMPLETED queue, together with its return value."),(0,i.yg)("p",null,(0,i.yg)("a",{parentName:"p",href:"questions/why-use-completed-queue.md"},"Quiz")))}p.isMDXComponent=!0}}]);