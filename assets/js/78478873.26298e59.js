"use strict";(self.webpackChunkso=self.webpackChunkso||[]).push([[7075],{5680:(e,n,t)=>{t.d(n,{xA:()=>c,yg:()=>h});var a=t(6540);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},c=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},m="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},d=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=p(t),d=i,h=m["".concat(s,".").concat(d)]||m[d]||g[d]||r;return t?a.createElement(h,o(o({ref:n},c),{},{components:t})):a.createElement(h,o({ref:n},c))}));function h(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var r=t.length,o=new Array(r);o[0]=d;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[m]="string"==typeof e?e:i,o[1]=l;for(var p=2;p<r;p++)o[p]=t[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}d.displayName="MDXCreateElement"},6386:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>g,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var a=t(8168),i=(t(6540),t(5680));const r={},o="Lab 11 - IO Optimizations",l={unversionedId:"IO/lab11",id:"IO/lab11",title:"Lab 11 - IO Optimizations",description:"Task: Ordered Client-Server Communication",source:"@site/docs/IO/lab11.md",sourceDirName:"IO",slug:"/IO/lab11",permalink:"/operating-systems/IO/lab11",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Lab 10 - Inter-Process Communication",permalink:"/operating-systems/IO/lab10"},next:{title:"Application Interaction",permalink:"/operating-systems/Application Interaction/"}},s={},p=[{value:"Task: Ordered Client-Server Communication",id:"task-ordered-client-server-communication",level:2},{value:"Task: Multiplexed Client Server",id:"task-multiplexed-client-server",level:2},{value:"Task: Async Server",id:"task-async-server",level:2},{value:"I/O Multiplexing",id:"io-multiplexing",level:2},{value:"The <code>epoll</code> API",id:"the-epoll-api",level:3},{value:"Asynchronous I/O",id:"asynchronous-io",level:2},{value:"Zero-Copy",id:"zero-copy",level:2},{value:"<code>sendfile()</code>",id:"sendfile",level:3},{value:"Guide: Benchmarking <code>sendfile()</code>",id:"guide-benchmarking-sendfile",level:2},{value:"Guide: Kernel Caching",id:"guide-kernel-caching",level:2},{value:"Caching in action",id:"caching-in-action",level:3},{value:"Guide: Async",id:"guide-async",level:2}],c={toc:p},m="wrapper";function g(e){let{components:n,...r}=e;return(0,i.yg)(m,(0,a.A)({},c,r,{components:n,mdxType:"MDXLayout"}),(0,i.yg)("h1",{id:"lab-11---io-optimizations"},"Lab 11 - IO Optimizations"),(0,i.yg)("h2",{id:"task-ordered-client-server-communication"},"Task: Ordered Client-Server Communication"),(0,i.yg)("p",null,"Navigate to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/io/ipc/drills/tasks/client-server/")," and run ",(0,i.yg)("inlineCode",{parentName:"p"},"make")," to generate the ",(0,i.yg)("inlineCode",{parentName:"p"},"support")," directory.\nThis exercise will guide you in creating a basic messaging protocol between a server and a client.\nAlthough in real-world applications a server typically handles multiple connections at once, here we focus on a single connection.\nHandling multiple connections is further explored in ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#i/o-multiplexing"},"I/O multiplexing"),"."),(0,i.yg)("p",null,"Our application protocol is defined as follows:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"The ",(0,i.yg)("strong",{parentName:"li"},"server")," listens for connections on ",(0,i.yg)("strong",{parentName:"li"},"localhost")," and a specified ",(0,i.yg)("strong",{parentName:"li"},"port"),"."),(0,i.yg)("li",{parentName:"ul"},"The ",(0,i.yg)("strong",{parentName:"li"},"client")," connects to ",(0,i.yg)("inlineCode",{parentName:"li"},"localhost:port"),"."),(0,i.yg)("li",{parentName:"ul"},"The ",(0,i.yg)("strong",{parentName:"li"},"client")," sends a message, which the ",(0,i.yg)("strong",{parentName:"li"},"server")," then prints, responds to, and the ",(0,i.yg)("strong",{parentName:"li"},"client")," prints the reply.\nThis sequence repeats in a loop."),(0,i.yg)("li",{parentName:"ul"},"The communication ends when either the ",(0,i.yg)("strong",{parentName:"li"},"client")," or the ",(0,i.yg)("strong",{parentName:"li"},"server")," sends the message ",(0,i.yg)("inlineCode",{parentName:"li"},"exit"),".")),(0,i.yg)("p",null,"Since we are blocking on ",(0,i.yg)("inlineCode",{parentName:"p"},"recv()"),", the message order is fixed - the client ",(0,i.yg)("strong",{parentName:"p"},"must")," initiate communication.\nIn real-world applications, this constraint can be avoided with ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#i/o-multiplexing"},"I/O multiplexing"),"."),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Open ",(0,i.yg)("inlineCode",{parentName:"p"},"support/client.c")," and complete the TODOs to enable message exchange with the server.\nTest your client by running ",(0,i.yg)("inlineCode",{parentName:"p"},"python server.py")," in one terminal and then ",(0,i.yg)("inlineCode",{parentName:"p"},"./client")," in another.\nIf correctly implemented, you should be able to exchange messages as outlined above."),(0,i.yg)("p",{parentName:"li"},(0,i.yg)("strong",{parentName:"p"},"Bonus Question:")," Why is it OK for the client to be implemented in C while the server is implemented in Python?")),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Open ",(0,i.yg)("inlineCode",{parentName:"p"},"support/server.c")," and complete the TODOs to enable message exchange with the client.\nTest your server by running ",(0,i.yg)("inlineCode",{parentName:"p"},"./server")," in one terminal and then ",(0,i.yg)("inlineCode",{parentName:"p"},"python client.py")," in another.\nIf implemented correctly, you should be able to exchange messages as outlined above."))),(0,i.yg)("p",null,"If you're having difficulties solving this exercise, go through ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab10#unix-sockets"},"the sockets API")," and ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab10#client-server-model"},"the client-server model"),"."),(0,i.yg)("h2",{id:"task-multiplexed-client-server"},"Task: Multiplexed Client Server"),(0,i.yg)("p",null,"Navigate to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/io/optimizations/drills/tasks/multiplexed-client-server")," and run ",(0,i.yg)("inlineCode",{parentName:"p"},"make")," to generate the ",(0,i.yg)("inlineCode",{parentName:"p"},"support")," files."),(0,i.yg)("p",null,"This task builds on the previous implementation of a ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#task-ordered-client-server-communication"},"client-server ordered communication"),".\nPreviously, the client and server followed a strict, sequential communication pattern: each peer had to send a message and wait for a reply before proceeding."),(0,i.yg)("p",null,"We plan to build a group chat where clients can send messages at any time, and each message is broadcast to all other connected clients.\nTo accomplish this, we\u2019ll implement I/O multiplexing mechanisms that notify us only when data is available on a file descriptor.\nThis non-blocking approach allows for smooth, unhindered communication between clients."),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"We\u2019ll use the ",(0,i.yg)("a",{parentName:"p",href:"https://man7.org/linux/man-pages/man7/epoll.7.html"},(0,i.yg)("inlineCode",{parentName:"a"},"epoll"))," interface to manage multiple file descriptors.\nBegin by opening ",(0,i.yg)("inlineCode",{parentName:"p"},"w_epoll.h")," and completing the TODOs.\nWe will define wrapper functions to ",(0,i.yg)("strong",{parentName:"p"},"add")," and ",(0,i.yg)("strong",{parentName:"p"},"remove")," file descriptors from the ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll")," instance, making the main code more readable.\n",(0,i.yg)("strong",{parentName:"p"},"Note:")," Ensure that each wrapper returns the result of the ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll_ctl()")," for error handling.")),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Complete the TODOs in ",(0,i.yg)("inlineCode",{parentName:"p"},"support/client.c")," to enable multiplexing of the available file descriptors.\nThe file descriptors are ",(0,i.yg)("inlineCode",{parentName:"p"},"stdin")," (for receiving user messages) and ",(0,i.yg)("inlineCode",{parentName:"p"},"sockfd")," (for communication with the server).\nUse ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll_create()"),", ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll_wait()"),", and the wrappers defined in ",(0,i.yg)("inlineCode",{parentName:"p"},"w_epoll.h")," to handle these descriptors without blocking.\nRemember to close the sockets before exiting."),(0,i.yg)("p",{parentName:"li"},"To test, start ",(0,i.yg)("inlineCode",{parentName:"p"},"python server.py")," in one terminal and run your client implementation in two separate terminals.\nIf successful, the clients should be able to communicate through the server.")),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Complete the TODOs in ",(0,i.yg)("inlineCode",{parentName:"p"},"support/server.c")," to multiplex I/O with clients.\nYou will need to create an ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll")," instance and dynamically ",(0,i.yg)("strong",{parentName:"p"},"add")," and ",(0,i.yg)("strong",{parentName:"p"},"remove")," clients as they connect and disconnect.\nUse ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll_create()"),", ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll_wait()"),", and the wrappers defined in ",(0,i.yg)("inlineCode",{parentName:"p"},"w_epoll.h")," to achieve this functionality.\n",(0,i.yg)("strong",{parentName:"p"},"Remember")," to remove the client sockets from the ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll")," instance before closing them."),(0,i.yg)("p",{parentName:"li"},"To test your implementation, run ",(0,i.yg)("inlineCode",{parentName:"p"},"./server")," in one terminal and ",(0,i.yg)("inlineCode",{parentName:"p"},"./client")," (or ",(0,i.yg)("inlineCode",{parentName:"p"},"python client.py"),") in two separate terminals.\nIf everything works correctly, the clients should be able to communicate with each other via the server."))),(0,i.yg)("p",null,"If you're having difficulties solving this exercise, go through the ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll")," API from ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#i/o-multiplexing"},"I/O Multiplexing"),"."),(0,i.yg)("h2",{id:"task-async-server"},"Task: Async Server"),(0,i.yg)("p",null,"Navigate to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/io/optimizations/drills/tasks/async-server")," and run ",(0,i.yg)("inlineCode",{parentName:"p"},"make")," to generate the ",(0,i.yg)("inlineCode",{parentName:"p"},"support")," files.\nEnter ",(0,i.yg)("inlineCode",{parentName:"p"},"support")," and run ",(0,i.yg)("inlineCode",{parentName:"p"},"make test-file.txt")," to generate the test file."),(0,i.yg)("p",null,"This task builds on the previous example of a ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#task-multiplexed-client-server"},"multiplexed client-server"),".\nThe server accepts connections from clients and downloads a file of ",(0,i.yg)("inlineCode",{parentName:"p"},"1 GB")," from each.\nAfter uploading the file, the clients close the connection."),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Open ",(0,i.yg)("inlineCode",{parentName:"p"},"server.c")," and complete the TODOs in the main function to setup IO multiplexing using ",(0,i.yg)("a",{parentName:"p",href:"https://man7.org/linux/man-pages/man7/epoll.7.html"},(0,i.yg)("inlineCode",{parentName:"a"},"epoll")),".\nUse ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll_create()"),", ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll_wait()"),", and the wrappers defined in ",(0,i.yg)("inlineCode",{parentName:"p"},"w_epoll.h")," to handle descriptors without blocking.\n",(0,i.yg)("strong",{parentName:"p"},"Remember")," to remove the client sockets from the ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll")," instance before closing them."),(0,i.yg)("p",{parentName:"li"},"To test, run ",(0,i.yg)("inlineCode",{parentName:"p"},"./server")," in one terminal and ",(0,i.yg)("inlineCode",{parentName:"p"},"./client")," in another terminal.s\nIf successful, the clients should print the upload progress.")),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"There is a problem with our current implementation.\nTry to start two clients at the same time - the first one will start uploading, and the second one will block at ",(0,i.yg)("inlineCode",{parentName:"p"},"connect()"),".\nThis happens because, even though we are multiplexing file descriptors on the server-side, it is busy with another client.\nTo account for this, complete the TODOs in ",(0,i.yg)("inlineCode",{parentName:"p"},"handle_client()")," to serve each client on a different process."),(0,i.yg)("p",{parentName:"li"},"To test, start ",(0,i.yg)("inlineCode",{parentName:"p"},"python server.py")," in one terminal and run your client implementation in two separate terminals.\nIf successful, the clients should be able to upload at the same time."))),(0,i.yg)("p",null,"If you're having difficulties solving this exercise, go through ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#asynchronous-i/o"},"Async I/O")," and ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#i/o-multiplexing"},"I/O Multiplexing"),"."),(0,i.yg)("h2",{id:"io-multiplexing"},"I/O Multiplexing"),(0,i.yg)("p",null,"I/O multiplexing is the ability to serve multiple I/O channels (or anything that can be referenced via a file descriptor / handle) simultaneously.\nIf a given application, such a server, has multiple sockets on which it serves connection, it may be the case that operating on one socket blocks the server.\nOne solution is using asynchronous operations, with different backends.\nThe other solution is using I/O multiplexing."),(0,i.yg)("p",null,"The classical functions for I/O multiplexing are ",(0,i.yg)("a",{parentName:"p",href:"https://man7.org/linux/man-pages/man2/select.2.html"},(0,i.yg)("inlineCode",{parentName:"a"},"select"))," and ",(0,i.yg)("a",{parentName:"p",href:"https://man7.org/linux/man-pages/man2/poll.2.html"},(0,i.yg)("inlineCode",{parentName:"a"},"poll")),".\nDue to several limitations, modern operating systems provide advanced (non-portable) variants to these:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"Windows provides ",(0,i.yg)("a",{parentName:"li",href:"https://learn.microsoft.com/en-us/windows/win32/fileio/i-o-completion-ports"},"I/O completion ports (",(0,i.yg)("inlineCode",{parentName:"a"},"IOCP"),")"),"."),(0,i.yg)("li",{parentName:"ul"},"BSD provides ",(0,i.yg)("a",{parentName:"li",href:"https://www.freebsd.org/cgi/man.cgi?kqueue"},(0,i.yg)("inlineCode",{parentName:"a"},"kqueue")),"."),(0,i.yg)("li",{parentName:"ul"},"Linux provides ",(0,i.yg)("a",{parentName:"li",href:"https://man7.org/linux/man-pages/man7/epoll.7.html"},(0,i.yg)("inlineCode",{parentName:"a"},"epoll()")),".")),(0,i.yg)("blockquote",null,(0,i.yg)("p",{parentName:"blockquote"},(0,i.yg)("strong",{parentName:"p"},"Note")," that I/O multiplexing is orthogonal to ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#asynchronous-i/o"},"asynchronous I/O"),".\nYou could tie them together if the completion of the asynchronous operation sends a notification that can be handled via a file descriptor / handle.\nThis is the case with Windows asynchronous I/O (called ",(0,i.yg)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/windows/win32/fileio/synchronous-and-asynchronous-i-o"},"overlapped I/O"),").")),(0,i.yg)("h3",{id:"the-epoll-api"},"The ",(0,i.yg)("inlineCode",{parentName:"h3"},"epoll")," API"),(0,i.yg)("p",null,"The ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll")," API allows user-space programs to efficiently monitor multiple file descriptors and be notified when one of them has data to read.\nIt provides a powerful, event-driven interface concentrated in three primary functions:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"int epoll_create1(int flags)"),": Creates an ",(0,i.yg)("inlineCode",{parentName:"li"},"epoll")," instance.\nThe ",(0,i.yg)("inlineCode",{parentName:"li"},"flags")," argument specifies additional options for the instance.\nThe default value is ",(0,i.yg)("inlineCode",{parentName:"li"},"0"),"."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout)"),": Waits for events on the monitored file descriptors.",(0,i.yg)("ul",{parentName:"li"},(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"epfd"),": The file descriptor returned by ",(0,i.yg)("inlineCode",{parentName:"li"},"epoll_create1()"),"."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"events"),": An array of ",(0,i.yg)("inlineCode",{parentName:"li"},"struct epoll_event")," that will store the events that have occurred.\nIt only contains events that are ready (i.e., received data)."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"maxevents"),": The maximum number of events that can be stored in the ",(0,i.yg)("inlineCode",{parentName:"li"},"events")," array."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"timeout"),": The maximum time (in milliseconds) that ",(0,i.yg)("inlineCode",{parentName:"li"},"epoll_wait()")," will block.\nA value of ",(0,i.yg)("inlineCode",{parentName:"li"},"-1")," means it will block indefinitely."))),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)"),": Modifies the set of file descriptors monitored by ",(0,i.yg)("inlineCode",{parentName:"li"},"epoll"),".",(0,i.yg)("ul",{parentName:"li"},(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"epfd"),": The file descriptor returned by ",(0,i.yg)("inlineCode",{parentName:"li"},"epoll_create1()"),"."),(0,i.yg)("li",{parentName:"ul"},"The ",(0,i.yg)("inlineCode",{parentName:"li"},"op")," argument specifies the operation to perform, which can be:",(0,i.yg)("ul",{parentName:"li"},(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"EPOLL_CTL_ADD"),": Adds a file descriptor to the monitoring list."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"EPOLL_CTL_MOD"),": Modifies an existing file descriptor\u2019s event list."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"EPOLL_CTL_DEL"),": Removes a file descriptor from the monitoring list."))),(0,i.yg)("li",{parentName:"ul"},"The ",(0,i.yg)("inlineCode",{parentName:"li"},"fd")," argument is the file descriptor to be added, modified, or removed."),(0,i.yg)("li",{parentName:"ul"},"The ",(0,i.yg)("inlineCode",{parentName:"li"},"event")," argument is a pointer to a ",(0,i.yg)("inlineCode",{parentName:"li"},"struct epoll_event")," that defines the events associated with the file descriptor.")))),(0,i.yg)("p",null,"The ",(0,i.yg)("a",{parentName:"p",href:"https://man7.org/linux/man-pages/man3/epoll_event.3type.html"},(0,i.yg)("inlineCode",{parentName:"a"},"struct epoll_event"))," is the core structure used to interact with ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll"),".\nIt is used to return events to user space after ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll_wait()")," is called and to pass parameters to ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll_ctl()")," when modifying the set of monitored file descriptors.\nWhile the internal workings of ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll")," are complex, understanding how to use these functions and structures will cover most use cases."),(0,i.yg)("p",null,"Here is an example demonstrating how to use the ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll")," interface:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-c"},'efd = epoll_create1(0)\nif (efd < 0) {...} // handle error\n\n// Add fd to monitored set\nstruct epoll_event ev;\nev.events = EPOLLIN;  // monitor fd for reading\nev.data.fd = fd;\nrc = epoll_ctl(efd, EPOLL_CTL_ADD, fd, &ev);\nif (rc < 0) {...} // handle error\n\nstruct epoll_event events[10];\nn = epoll_wait(efd, events, 10, -1);  // Wait indefinitely\nif (n < 0) {...} // handle error\n\n// Iterate through the events to get active file descriptors\nfor (int i = 0; i < n; i++)\n    printf("%d received data\\n", events[i].data.fd);\n')),(0,i.yg)("p",null,"Test your ",(0,i.yg)("inlineCode",{parentName:"p"},"epoll")," understanding by implementing ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#task-multiplexed-client-server"},"I/O multiplexing in a client-server app"),"."),(0,i.yg)("h2",{id:"asynchronous-io"},"Asynchronous I/O"),(0,i.yg)("p",null,"Asynchronous I/O (async I/O) provides an efficient way to handle input/output operations that are typically slower than CPU operations by allowing programs to continue executing while waiting for I/O operations to complete.\nHere\u2019s a breakdown of I/O operation types and how asynchronous I/O compares to synchronous operations:"),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},(0,i.yg)("strong",{parentName:"p"},"Synchronous Blocking Operation"),":"),(0,i.yg)("ul",{parentName:"li"},(0,i.yg)("li",{parentName:"ul"},"This is the simplest and most common form of I/O (e.g., ",(0,i.yg)("inlineCode",{parentName:"li"},"read()")," and ",(0,i.yg)("inlineCode",{parentName:"li"},"write()"),")."),(0,i.yg)("li",{parentName:"ul"},"It\u2019s ",(0,i.yg)("strong",{parentName:"li"},"synchronous"),", meaning the program waits for a response to proceed."),(0,i.yg)("li",{parentName:"ul"},"It\u2019s ",(0,i.yg)("strong",{parentName:"li"},"blocking"),", so if the requested data isn\u2019t available (e.g., no data in the buffer for ",(0,i.yg)("inlineCode",{parentName:"li"},"read()"),"), the program waits for the operation to finish."))),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},(0,i.yg)("strong",{parentName:"p"},"Synchronous Non-blocking Operation"),":"),(0,i.yg)("ul",{parentName:"li"},(0,i.yg)("li",{parentName:"ul"},"This gives more control, especially in situations where waiting isn\u2019t ideal."),(0,i.yg)("li",{parentName:"ul"},"Opening a file using ",(0,i.yg)("inlineCode",{parentName:"li"},"open()")," alongside ",(0,i.yg)("inlineCode",{parentName:"li"},"O_NONBLOCK")," flag ensures the operation returns immediately instead of blocking."),(0,i.yg)("li",{parentName:"ul"},"If data isn\u2019t available right away, the operation notifies the program, which can try again later, avoiding unnecessary waiting."))),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},(0,i.yg)("strong",{parentName:"p"},"Asynchronous Operation"),":"),(0,i.yg)("ul",{parentName:"li"},(0,i.yg)("li",{parentName:"ul"},"Here, the function call returns immediately, allowing the program to continue ",(0,i.yg)("strong",{parentName:"li"},"without waiting for the result"),"."),(0,i.yg)("li",{parentName:"ul"},"A notification or callback is sent when the operation completes, or the program can check its status periodically.")))),(0,i.yg)("p",null,"Keep in mind the async I/O is not the same thing as I/O multiplexing.\nWhile both techniques improve I/O efficiency, they\u2019re conceptually different:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"Asynchronous I/O")," schedules operations concurrently, allowing the program to proceed without blocking."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("a",{parentName:"li",href:"/operating-systems/IO/lab11#i/o-multiplexing"},(0,i.yg)("strong",{parentName:"a"},"I/O Multiplexing"))," (e.g., ",(0,i.yg)("inlineCode",{parentName:"li"},"select()"),", ",(0,i.yg)("inlineCode",{parentName:"li"},"poll()"),", ",(0,i.yg)("inlineCode",{parentName:"li"},"epoll()"),") monitors multiple channels simultaneously and informs the program when a channel has data ready.\nBlocking could still occur if the program cannot proceed without data from a channel.")),(0,i.yg)("p",null,"Think of them as ",(0,i.yg)("strong",{parentName:"p"},"complementary"),": multiplexing helps monitor multiple channels, while async I/O allows the program to do other things while waiting."),(0,i.yg)("p",null,"There are several ways asynchronous I/O can be implemented in practice:"),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},(0,i.yg)("strong",{parentName:"p"},"Multiprocess Backend"),": Each request runs in a ",(0,i.yg)("strong",{parentName:"p"},"separate process"),", isolating tasks and preventing blocking between them."),(0,i.yg)("pre",{parentName:"li"},(0,i.yg)("code",{parentName:"pre",className:"language-c"},"// Handle requests with processes\nvoid handle_client_proc(int client_sockfd) {\n   pid_t pid = fork();\n   if (pid < 0) // handle error\n\n   if (pid == 0) {  // Child process: handle client connection\n      close(server_sockfd);  // Close the server socket in the child\n\n      {...}  // compute and send answer\n\n      close(client_sockfd);  // Close client socket when done\n      exit(0);              // Exit child process\n   }\n\n   close(client_sockfd);     // close client socket in parent\n}\n"))),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},(0,i.yg)("strong",{parentName:"p"},"Multithreaded Backend"),": Each request runs in a ",(0,i.yg)("strong",{parentName:"p"},"separate thread"),", allowing concurrent operations within the same process."),(0,i.yg)("pre",{parentName:"li"},(0,i.yg)("code",{parentName:"pre",className:"language-c"},"// Handle requests with threads\nvoid* handler(void* arg) {\n   int client_sockfd = *(int*)arg;\n\n   {...}                   // compute and send answer\n   close(client_sockfd);   // Close client socket when done\n\n   return NULL;\n}\n\nvoid handle_client_thread(int sockfd) {\n   int *sockfd_p = malloc(sizeof(int));  // use the heap to pass the address\n   *sockfd_p = sockfd;\n\n   int rc = pthread_create(&thread_id, NULL, handler, client_sock_ptr);\n   if (rc < 0)                 // handle error\n   pthread_detach(thread_id);  // Let the thread clean up after itself\n}\n"))),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},(0,i.yg)("strong",{parentName:"p"},"Event-based Backend"),": An action is scheduled with a ",(0,i.yg)("strong",{parentName:"p"},"callback"),", which is invoked upon completion, using event loops to manage tasks.\nA callback is simply a function pointer, allowing the system to execute the function later or when a specific event is triggered."))),(0,i.yg)("p",null,"Test your understanding by solving the ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#task-async-server"},"Async Server task"),"."),(0,i.yg)("h2",{id:"zero-copy"},"Zero-Copy"),(0,i.yg)("p",null,"Imagine a server that responds with files that it stores locally.\nIts actions would be those highlighted in the image below:"),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},"Receive a new request and extract the filename"),(0,i.yg)("li",{parentName:"ol"},"Read the filename from the disk into memory"),(0,i.yg)("li",{parentName:"ol"},"Send the file from memory to the client")),(0,i.yg)("p",null,(0,i.yg)("img",{alt:"Client-Server Steps",src:t(1975).A})),(0,i.yg)("p",null,(0,i.yg)("a",{parentName:"p",href:"Questions/server-copies"},"Quiz: How many copies does the OS make?")),(0,i.yg)("p",null,"As you might have guessed, 2 of these copies are useless.\nSince the app doesn't modify the file, there's no need for it to store the file in its own buffer.\nIt would be more efficient to use ",(0,i.yg)("strong",{parentName:"p"},"a single")," kernel buffer as intermediate storage between the disk and the NIC (Network Interface Card), as shown in the image below."),(0,i.yg)("p",null,(0,i.yg)("img",{alt:"Server Copies - Zero-Copy",src:t(6317).A})),(0,i.yg)("p",null,'For an easier comparison with the "classic" ',(0,i.yg)("inlineCode",{parentName:"p"},"read()")," + ",(0,i.yg)("inlineCode",{parentName:"p"},"send()")," model, here's the first version again:"),(0,i.yg)("p",null,(0,i.yg)("img",{alt:"Server Copies - Read-Send",src:t(7366).A})),(0,i.yg)("p",null,"It should be obvious that the former approach is more efficient than the latter."),(0,i.yg)("p",null,(0,i.yg)("a",{parentName:"p",href:"Questions/fewer-than-2-copies"},"Quiz: Almost zero copies")),(0,i.yg)("p",null,"These diagrams capture the essence of ",(0,i.yg)("strong",{parentName:"p"},"zero-copy"),": transferring data directly between kernel buffers, avoiding intermediate user-space buffers.\nThis approach is ideal for serving requests, whether forwarding data between clients or reading from disk.\nIt relies on the OS to retrieve and send data efficiently without extra copying steps."),(0,i.yg)("h3",{id:"sendfile"},(0,i.yg)("inlineCode",{parentName:"h3"},"sendfile()")),(0,i.yg)("p",null,"The syscall with which we can leverage ",(0,i.yg)("strong",{parentName:"p"},"zero-copy")," is called ",(0,i.yg)("a",{parentName:"p",href:"https://man7.org/linux/man-pages/man2/sendfile.2.html"},(0,i.yg)("inlineCode",{parentName:"a"},"sendfile()")),".\nHere are some practical examples on how to use it:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-c"},'// file to file\nint in_fd = open("input_file.txt", O_RDONLY);  // src\nint out_fd = open("output_socket", O_WRONLY);  // dst\n\nssize_t bytes_sent = sendfile(out_fd, in_fd, &offset, 4096); // Transfer 4096 bytes\nif (bytes_sent < 0) {...} // handle error\n')),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-c"},'// file to network\nint in_fd = open("input_file.txt", O_RDONLY);  // src\nint sockfd = socket(AF_INET, SOCK_STREAM, 0);  // dst\n\nint rc = connect(sock_fd, &server_addr, sizeof(server_addr));\nif (rc < 0) {...} // handle error\n\nssize_t bytes_sent = sendfile(out_fd, in_fd, &offset, 4096); // Transfer 4096 bytes\nif (bytes_sent < 0) {...} // handle error\n')),(0,i.yg)("p",null,"You can read a slightly more detailed article about zero-copy ",(0,i.yg)("a",{parentName:"p",href:"https://developer.ibm.com/articles/j-zerocopy/"},"here"),"."),(0,i.yg)("h2",{id:"guide-benchmarking-sendfile"},"Guide: Benchmarking ",(0,i.yg)("inlineCode",{parentName:"h2"},"sendfile()")),(0,i.yg)("p",null,"Navigate to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/io/optimizations/guides/benchmarking-sendfile/support")," and run ",(0,i.yg)("inlineCode",{parentName:"p"},"make")," to prepare the test file."),(0,i.yg)("p",null,(0,i.yg)("inlineCode",{parentName:"p"},"sendfile()")," transfers data between two file descriptors directly within the kernel, bypassing user-space buffers.\nThis process is known as ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#zero-copy"},"zero-copy"),".\nHaving established that ",(0,i.yg)("inlineCode",{parentName:"p"},"sendfile()")," is likely faster than traditional I/O operations, it's time to put this theory to the test!"),(0,i.yg)("p",null,"The code in ",(0,i.yg)("inlineCode",{parentName:"p"},"server.py")," creates two threads that behave nearly identically.\nOne listens on port ",(0,i.yg)("inlineCode",{parentName:"p"},"8081")," and handles connections using ",(0,i.yg)("inlineCode",{parentName:"p"},"read()")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"send()"),", while the other listens on port ",(0,i.yg)("inlineCode",{parentName:"p"},"8082")," and uses ",(0,i.yg)("inlineCode",{parentName:"p"},"sendfile()"),".\nStart the server in one terminal with ",(0,i.yg)("inlineCode",{parentName:"p"},"python server.py"),".\nIn a second terminal, run ",(0,i.yg)("inlineCode",{parentName:"p"},"benchmark_client.py read-send")," followed by ",(0,i.yg)("inlineCode",{parentName:"p"},"benchmark_client.py sendfile")," to compare the performance."),(0,i.yg)("p",null,"The results below are generic, and your outcomes may vary significantly depending on factors such as disk performance, network interface card (NIC), kernel version, Python version, and system load."),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-console"},"student@os:/.../benchmarking-sendfile/support$ python3 benchmark_client.py read-send\nTime taken: 7.175773588009179 seconds\n\nstudent@os:/.../benchmarking-sendfile/support$ python3 benchmark_client.py sendfile\nTime taken: 3.71454380400246 seconds\n")),(0,i.yg)("p",null,"Using ",(0,i.yg)("inlineCode",{parentName:"p"},"sendfile()")," ",(0,i.yg)("strong",{parentName:"p"},"halves the number of copies")," required, reducing it from 4 to 2.\nThis should translate to a roughly halved running time as well, making ",(0,i.yg)("inlineCode",{parentName:"p"},"sendfile()")," a clear performance improvement over traditional methods."),(0,i.yg)("p",null,"You can explore another example of ",(0,i.yg)("strong",{parentName:"p"},"zero-copy")," in practice in this ",(0,i.yg)("a",{parentName:"p",href:"Questions/mmap-read-write-benchmark"},"Quiz: Why is ",(0,i.yg)("inlineCode",{parentName:"a"},"cp")," faster than ",(0,i.yg)("inlineCode",{parentName:"a"},"mmap()"),"-based ",(0,i.yg)("inlineCode",{parentName:"a"},"cp")),"."),(0,i.yg)("h2",{id:"guide-kernel-caching"},"Guide: Kernel Caching"),(0,i.yg)("p",null,"I/O is critical to system efficiency, but also often its weakest link.\nTechniques to improve I/O performance include ",(0,i.yg)("a",{parentName:"p",href:"guides/libc-FILE-struct/"},"buffering"),", ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#zero-copy"},"zero-copy"),", and ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#asynchronous-i/o"},"async I/O"),".\nAmong these, buffering is the most common and powerful."),(0,i.yg)("p",null,"Remember ",(0,i.yg)("inlineCode",{parentName:"p"},"buffering/support/benchmark_buffering.sh")," or ",(0,i.yg)("inlineCode",{parentName:"p"},"file-mappings/support/benchmark_cp.sh"),".\nThey both used this line:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-bash"},'sudo sh -c "sync; echo 3 > /proc/sys/vm/drop_caches"\n')),(0,i.yg)("p",null,"The line invalidates caches, forcing the OS to perform I/O operations directly from the disk.\nThis ensures that the scripts benchmark the C code's performance alone, without any speedup from cached data."),(0,i.yg)("p",null,"The kernel goes even further with ",(0,i.yg)("strong",{parentName:"p"},"buffering"),".\nThis time, it\u2019s at a level beyond syscalls like ",(0,i.yg)("inlineCode",{parentName:"p"},"read()")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"write()"),", using a strategy known as ",(0,i.yg)("strong",{parentName:"p"},"caching"),".\nWhile buffering helps with handling the ",(0,i.yg)("strong",{parentName:"p"},"next data")," efficiently by reading in advance or delaying writes, caching is about speeding up repeated access to the ",(0,i.yg)("strong",{parentName:"p"},"same data"),".\nJust as your browser caches frequently visited pages or your CPU caches recent addresses, the OS caches files that are accessed often, such as logs or configuration files."),(0,i.yg)("p",null,"When the OS encounters a file access, it stores portions of that file in memory so that subsequent requests can read or modify data from RAM rather than waiting on the slower disk.\nThis makes I/O faster."),(0,i.yg)("h3",{id:"caching-in-action"},"Caching in action"),(0,i.yg)("p",null,"Navigate to ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/io/optimizations/guides/kernel-caching/support")," and run ",(0,i.yg)("inlineCode",{parentName:"p"},"make")," to create a large file that we'll use for benchmarking.\nWe have two scripts to benchmark the ",(0,i.yg)("inlineCode",{parentName:"p"},"cp")," command with and without caching:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-console"},"student@os:/.../kernel-caching/support$ ./benchmark_cp.sh\nmake: 'large-file.txt' is up to date.\nBenchmarking cp on a 1 GB file...\n\nreal    0m1.473s\nuser    0m0.001s\nsys     0m0.985s\n\nstudent@os:/.../kernel-caching/support$ ./benchmark_cp_allow_caching.sh\nmake: 'large-file.txt' is up to date.\nBenchmarking cp on a 1 GB file...\n\nreal    0m0.813s\nuser    0m0.000s\nsys     0m0.837s\n")),(0,i.yg)("p",null,"Each subsequent benchmark actually reads the data from the caches populated or refreshed by the previous one.\nSo running the script multiple times might improve the results."),(0,i.yg)("p",null,"You can use ",(0,i.yg)("inlineCode",{parentName:"p"},"free -h")," to view how much data your kernel is caching.\nLook at the ",(0,i.yg)("inlineCode",{parentName:"p"},"buff/cache")," column.\nOne possible output is shown below.\nIt says the OS is caching 7 GB of data."),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-console"},"student@os:~$ free -h\n              total        used        free      shared  buff/cache   available\nMem:           15Gi       8,1Gi       503Mi       691Mi       7,0Gi       6,5Gi\nSwap:         7,6Gi       234Mi       7,4Gi\n")),(0,i.yg)("h2",{id:"guide-async"},"Guide: Async"),(0,i.yg)("p",null,"Enter the ",(0,i.yg)("inlineCode",{parentName:"p"},"chapters/io/optimizations/guide/async/")," folder for some implementations of a simple request-reply server in C.\nHere we have the implementation of a server that computes the n-th fibonacci number.\nThe server serves requests in different ways:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"synchronous")," server: ",(0,i.yg)("inlineCode",{parentName:"li"},"server.c")),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"multiprocess")," server: ",(0,i.yg)("inlineCode",{parentName:"li"},"mp_server.c")),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"multithreaded")," server: ",(0,i.yg)("inlineCode",{parentName:"li"},"mt_server.c"))),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Note:")," There is no asynchronous C variant, because of the unstable API of ",(0,i.yg)("a",{parentName:"p",href:"https://pagure.io/libaio"},(0,i.yg)("inlineCode",{parentName:"a"},"libaio"))," and ",(0,i.yg)("a",{parentName:"p",href:"https://unixism.net/loti/what_is_io_uring.html"},(0,i.yg)("inlineCode",{parentName:"a"},"io_uring")),"."),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Benchmark the synchronous server to have a reference point.\nRun ",(0,i.yg)("inlineCode",{parentName:"p"},"./server 2999")," in one terminal and ",(0,i.yg)("inlineCode",{parentName:"p"},"time ./client_bench.sh 2999")," in another.\n",(0,i.yg)("inlineCode",{parentName:"p"},"client_bench.sh")," we'll run ",(0,i.yg)("inlineCode",{parentName:"p"},"8")," instances of ",(0,i.yg)("inlineCode",{parentName:"p"},"client.py")," that make a request."),(0,i.yg)("pre",{parentName:"li"},(0,i.yg)("code",{parentName:"pre",className:"language-console"},"student@os:~/async/support$ time ./client_bench.sh 2000\n[...]\nroot: Connected to localhost:2000\nroot: Sending 30\nfunction(30): 1346269\n\nreal    0m1.075s\nuser    0m0.301s\nsys     0m0.029s\n")),(0,i.yg)("p",{parentName:"li"},"The value you obtain might be different, but you should observe a speed-up when benchmarking the other two solutions.")),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Benchmark the multiprocess and multithreaded alternatives and see which one got the best speed increase.\nYou can obtain more relevant values by tweaking parameters in ",(0,i.yg)("inlineCode",{parentName:"p"},"client_bench.sh"),".\nFor example, you could increase the ",(0,i.yg)("strong",{parentName:"p"},"number of clients")," or the ",(0,i.yg)("strong",{parentName:"p"},"fibonacci value to compute"),".")),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Begin by benchmarking the synchronous server to establish a baseline.\nRun ",(0,i.yg)("inlineCode",{parentName:"p"},"./server 2999")," in one terminal and ",(0,i.yg)("inlineCode",{parentName:"p"},"time ./client_bench.sh 2999")," in another.\nThe ",(0,i.yg)("inlineCode",{parentName:"p"},"client_bench.sh")," script will initiate ",(0,i.yg)("inlineCode",{parentName:"p"},"8")," instances of ",(0,i.yg)("inlineCode",{parentName:"p"},"client.py"),", each making a request.\nThe output might look like this:"),(0,i.yg)("pre",{parentName:"li"},(0,i.yg)("code",{parentName:"pre",className:"language-console"},"student@os:~/async/support$ time ./client_bench.sh 2000\n[...]\nroot: Connected to localhost:2000\nroot: Sending 30\nfunction(30): 1346269\n\nreal    0m1.075s\nuser    0m0.301s\nsys     0m0.029s\n")),(0,i.yg)("p",{parentName:"li"},"Although the actual value may vary, you should observe a noticeable speed-up when testing the other two solutions.")),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},"Next, benchmark the multiprocess and multithreaded alternatives to determine which offers the best performance improvement.\nTo obtain more meaningful results, adjust parameters in ",(0,i.yg)("inlineCode",{parentName:"p"},"client_bench.sh"),", such as increasing the ",(0,i.yg)("strong",{parentName:"p"},"number of clients")," or the ",(0,i.yg)("strong",{parentName:"p"},"Fibonacci value to compute"),"."))),(0,i.yg)("p",null,"If you're having difficulties understanding the support code, go through ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#asynchronous-i/o"},"this reading material"),".\nIf you want to practice this yourself, go through the ",(0,i.yg)("a",{parentName:"p",href:"/operating-systems/IO/lab11#task-async-server"},"Async Server task"),"."))}g.isMDXComponent=!0},1975:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/client-server-file-c21c08a102e6557188be7f080092a12c.svg"},7366:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/server-copies-normal-7e82d53d42a478d0313cb85917335f94.svg"},6317:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/server-copies-zero-copy-fc1fa1195f2444d92486d7d63dfc81a3.svg"}}]);